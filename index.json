[{"content":"I have decided to have a go at Go (pun intended!).\nThe reasons are less important than the decision itself, so I will not discuss them in this blog. Instead, I will focus on the journey and will document the experience in a series of posts (hopefully, more to come!).\nAnyone who has worked with a programming language professionally knows that learning a programming language involves more than learning syntax. Here is a list of things that I feel I need to learn if I want to be productive in Go (in no particular order) -\nSetting up relevant tools and being comfortable with them The language syntax Language APIs 3rd party libraries and frameworks Debugging in Go Compiling and packaging applications with Go Set up CI/CD Different failure modes and language quarks and learning how to watch out for them Monitoring for failures, including learning how to collect metrics I am currently at stage 2, trying to learn the language syntax. I expect to jump back and forth between different stages as I continue learning Go.\nInstalling Go Installing Go on my machine was relatively easy as I am on a Mac. All I had to do was use brew:\nbrew install go I verified my Go installation with:\ngo version which printed:\ngo version go1.20.1 darwin/arm64 Writing my first hello world script Next, it was time to write my first ever hello world in Go. I used Visual Studio Code to create a file named hello.go with the following content -\n// Go organises code in packages! Similar to Java package main // I can import other packages and reuse their code import \u0026#34;fmt\u0026#34; // This is how I can define a function in Go func main() { fmt.Print(\u0026#34;Hello World\\n\u0026#34;) } Now it is time to compile and run the code. I opened up the terminal, navigated to the directory containing the file, and executed:\ngo run hello.go The go run command compiled my script, built a native binary, and simultaneously executed it. Which then printed the expected output in the command line:\nHello World Success!\nLike Java, Go also has the concept of packages. I am still not fully aware of all the rules and gotchas, but I assume their purpose is similar to Java - they have been designed to group relevant code under a common namespace.\nI also learned that packages could decide to expose functions/variables to other packages. To do that, I have to define a function with a capital letter, and Go automatically assumes that it is intended to be used from other packages. This is why the Print function starts with a capital P.\nAnother observation is that if I change my package name to something else, like hellopackage, the code no longer compiles. Instead, I get the following error message:\npackage command-line-arguments is not a main package The package containing the main function must also be named main. This makes me wonder how people organise code in Go. Do they use reversed company domain name to name packages (i.e., com.sayemahmed) and then have only one package named main with only the main function to bootstrap the application? Or do they use something else?\ngo build go run isn\u0026rsquo;t the only way to build a Go script. We have another command at our disposal - go build - which compiles the script and generates a native executable binary:\ngo build -o hello_world hello.go I used the -o flag to specify a name for the binary file.\nThe compilation process reminded me of how I used to compile C/C++ files with GCC (gcc hello.c -o hello would be equivalent for a C file). With Java, however, I hardly needed to generate a native binary file (though I could, using GraalVM). Most of the times I have used Maven to build and deploy my web applications.\nWhat are the differences between go run and go build? The go run command takes either a single file, a list of files, or the name of a package. It then compiles the code and creates a native binary file in a temporary directory, executes the binary, and then deletes it immediately.\nThe go build command also takes either a single file, a list of files, or the name of a package. However, it only compiles the code and creates a native binary. We can use the -o flag with this command to set the name of the compiled binary.\nBuilt-in tools Besides the compiler, Go comes with many helpful tools with default installation. One such tool is go fmt which reformats code based on official standards. I was pleased to find out Go has an officially recommended formatting which is enforced during compile time! Ha! No more fighting over tabs vs spaces!!\nThe reason Go comes with standardised formatting seems to be easier tooling support. People claim that it makes it easy to write tools that manipulate Go source code, which makes it easy to write code generation tools. Nice.\nSimilar to a formatter, Go installation also includes a linter, a dependency manager, and a test runner. I have yet to try them out.\nMy first real script A few weeks ago, I needed to prepare a report. The report contained some information I collected over the last year. It was a ~500 lines file, and I wanted to check it had no duplicates before submitting it. I wrote a Go script to automate the process. The entire script is given below:\npackage main import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // First argument is the full path to the binary when // executed with `go run` if len(os.Args) != 2 { fmt.Println(\u0026#34;Usage: \u0026lt;exeutable\u0026gt; \u0026lt;full-path\u0026gt;\u0026#34;) return } fileName := os.Args[1] readFile, err := os.Open(fileName) if err != nil { fmt.Println(\u0026#34;Error while trying to open file\u0026#34;, err) } fileScanner := bufio.NewScanner(readFile) fileScanner.Split(bufio.ScanLines) // https://stackoverflow.com/a/34020023 set := make(map[string]struct{}) // https://dave.cheney.net/2014/03/25/the-empty-struct var empty struct{} for fileScanner.Scan() { line := strings.TrimSpace(fileScanner.Text()) if line == \u0026#34;\u0026#34; { continue } _, found := set[line] if found { fmt.Println(\u0026#34;Duplicate exists: \u0026#34;, line) } else { set[line] = empty } } readFile.Close() } I invoked the script as follows:\ngo run my-script.go ~/Documents/my-report.md Which then displayed all the duplicate lines in my-report.md file.\nI first learned how to pass command line arguments to a Go script. To do that, I needed to import the built-in os package and use it\u0026rsquo;s Args array. It looks like arrays in Go work similarly to Java and C - zero-based and indexed using []. The first element contains the executable\u0026rsquo;s name (in my case, it was something like /var/folders/mr/k_b0wtwd11q66p3z3787w9082200gq/T/go-build907299260/b001/exe/my-script). Starting from the second element, we can access any passed-in arguments. The script expects the file name, which should be checked for duplicates, so we access the file name at index 1.\nNext, I learned that to find the length of an array, I need to use the built-in len function. This is similar to how the len function in Python works.\nThe line:\nfileName := os.Args[1] declares and simultaneously initialises a variable named fileName with the name of our file. Go seems to allow a couple of ways to declare variables - one using var and the other without it. The above line for example could have also been written as:\n// Declare the variable first, with explicit type var fileScanner *bufio.Scanner // Initialise the variable fileScanner = bufio.NewScanner(readFile) There are some differences between the two approaches. For example, we can only use := within a function. It can also infer the variable type automatically as we are required to specify a value immediately.\nOn the other hand, we can use = outside a function as well. It also cannot infer the type of a variable automatically.\nWhen I saw the * in the type, I started thinking - does Go have explicit pointers like C? And it seems it does! That means caring about Dangling Pointers and SegFaults and memory safety and all that!\nThe following line opens the file for reading:\nreadFile, err := os.Open(fileName) I didn\u0026rsquo;t specify file open (i.e., read-write/append only/read-only) mode when calling Open, but I assume there must be a way to do it.\nOne interesting thing to note is how I used two variables to store the return values from Open. It looks similar to how Python can return multiple values from a method (which it converts into a Tuple). I am not 100% sure whether something similar is happening here. The Go by Example site mentions multiple return values, but it doesn\u0026rsquo;t explain how it actually works under the hood.\nAlso, after looking at some examples, it seems many functions in Go often return a couple of return values, especially the ones that do some I/O or have a chance of running into errors/issues. In Java, we used to throw exceptions when an I/O failed, but in Go, the convention is to return a second value describing the error.\nThe following two lines:\nfileScanner := bufio.NewScanner(readFile) fileScanner.Split(bufio.ScanLines) instantiates and configures something like a Scanner to read the file line by line.\nMy initial idea was to create a Set where I store the lines after reading from the file. Then, if I ever find another matching line by doing a simple contains check, I have found a duplicate. While trying to translate this idea into Go code, I discovered that it does not have any built-in Set type. It does have a Map, and the recommendation was to use it to simulate a Set, which I did:\nset := make(map[string]struct{}) I also came across empty struct. It seems Go does not have anything that looks like a Java class, but it does have Structures like in C. An empty struct is a special kind of structure in that it does not occupy any memory. And so, simulating a Set of strings with a Map of String to empty struct was the most space-efficient way.\nThe next few lines are relatively easy to understand - we stream through the lines in the files and check for duplicates. The interesting bit here is the line:\n_, found := set[line] which shows that, like some programming languages i.e., Scala Go also supports _ as a way to ignore values when we don\u0026rsquo;t care about them.\nFinal thoughts After writing my first script, my first impression was that Go is between C and Java. It has pointers like in C, and it has packages like Java. Its similarity to C might be why people often say that Go applications have less resource footprint. On the other hand, I wonder if Go has something like a Spring-framework, which removes a lot of boilerplate for anyone developing applications in Java.\nBut all in all, I like my initial brush with Go.\n","permalink":"https://www.sayemahmed.com/posts/my-first-brush-with-go/","summary":"I have decided to have a go at Go (pun intended!).\nThe reasons are less important than the decision itself, so I will not discuss them in this blog. Instead, I will focus on the journey and will document the experience in a series of posts (hopefully, more to come!).\nAnyone who has worked with a programming language professionally knows that learning a programming language involves more than learning syntax. Here is a list of things that I feel I need to learn if I want to be productive in Go (in no particular order) -","title":"My First Brush With Go"},{"content":"Introduction One of my all-time favourite articles is The Law of Leaky Abstractions by Joel Spolsky. In the article, Joel explains how non-trivial abstractions that make software development more manageable often break. And when they do, we need to understand how they truly work so we can fix them quickly.\nThis is the reason I value learning from first principles. Over the years, I have often applied this learning style to learn more about the tools I use regularly. In this blog post, I will share my learnings on ArrayList, an implementation of List, by building a copy implementation from scratch.\nPlease note that we will not implement a production-grade implementation. Instead, we will focus on implementing the most commonly used list methods to get a feel for how they work and thus understand their use cases better.\nCreating our custom ArrayList class Let\u0026rsquo;s declare the initial skeleton of the implementation -\npublic class CustomArrayList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt; { private Object[] elements; public CustomArrayList() { elements = new Object[?]; } } The official doc says that List implementations should support holding an arbitrary number of elements. However, we need to specify a size when creating the array. If we specify a large size, then we might waste memory. However, setting a shorter length puts a limitation on our capacity. So what do we do?\nOne way to get around this limitation is to create an array with a small capacity first and then resize it whenever we run out of space. Let\u0026rsquo;s go ahead and declare a 1-element array -\nelements = new Object[1]; We could also consider passing the size during construction if we have a rough idea of how many elements we will store in this list. This would help us to initialise the array more efficiently as we would need less resizing. We could provide another constructor which would accept an initialCapacity as an argument and use it to initialise the array -\npublic class CustomArrayList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt; { private Object[] elements; public CustomArrayList() { this(1); } public CustomArrayList(int initialCapacity) { elements = new Object[initialCapacity]; } } This is why it\u0026rsquo;s always better to instantiate ArrayList using capacity if we know it in advance. It avoids unnecessary resizing.\nImplementing methods add(element) We will implement the add method first, which is supposed to append the specified element to the end of this list -\n@Override public boolean add(E element) { // If the insertion is successful, it should return true. // Otherwise, it should return false. // This method should never replace any existing elements. return false; } Before appending the given element in the array, we need to know the next available position. We will define a new instance field, nextIndex, pointing to the next free slot in the array:\npublic class CustomArrayList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt; { private Object[] elements; // Contains 0 by default private int nextIndex; } Once defined, let\u0026rsquo;s continue our add implementation -\n@Override public boolean add(E element) { elements[nextIndex] = element; nextIndex++; return true; } How do we resize the array when it\u0026rsquo;s full? One way to do it is to create a new array, copy all the elements from the existing array, and then point elements to this new array:\n@Override public boolean add(E element) { if (nextIndex == elements.length) { Object[] copy = new Object[nextIndex + 1]; for (int i = 0; i \u0026lt; nextIndex; i++) { copy[i] = elements[i]; } elements = copy; } elements[nextIndex] = element; nextIndex++; return true; } What about performance? When we add a 2nd element to our list, we copy the existing element to the new array. On the 3rd add, the loop will copy two elements. Continuing like this, we can say that on N-th add, we will copy (N - 1) elements. To get the total number of copies required for the first N add, we sum them up = 1 + 2 + 3 + ... + (N - 1) = (N - 1) x N / 2.\nAdding the first N elements thus has an amortised time complexity of O(N^2). This means that if we double the size of the elements being added, the total time needed will increase 4-fold. Can we do better?\nThankfully, we can. Instead of increasing the capacity by one, we will double it:\n@Override public boolean add(E element) { if (nextIndex == elements.length) { Object[] copy = new Object[nextIndex * 2]; for (int i = 0; i \u0026lt; nextIndex; i++) { copy[i] = elements[i]; } elements = copy; } elements[nextIndex] = element; nextIndex++; return true; } The amortised time complexity will now reduce to O(N). Like before, the 2nd add will copy one element. But before the 3rd add, our implementation will double the size of the elements array, so the 4th add won\u0026rsquo;t need to resize it again. The 5th add will again double the capacity and copy the existing 4 elements, but then the 6th, 7th, and 8th calls won\u0026rsquo;t trigger a resize.\nWe can improve the actual performance even further by acknowledging a property of arrays called Data Locality. Data Locality guarantees that array elements are always stored in consecutive memory locations.\nSo rather than copying one element at a time, how about we copy blocks of memory instead? The System class has one such method, arraycopy, which we can use for this purpose:\n@Override public boolean add(E element) { if (nextIndex == elements.length) { Object[] copy = new Object[nextIndex * 2]; System.arraycopy(elements, 0, copy, 0, nextIndex); elements = copy; } elements[nextIndex] = element; nextIndex++; return true; } We can better understand the performance boost by looking at approximate latency numbers from this chart. As we can see, reading ~1MB of sequential data from main memory takes about ~1 microsecond. On the other hand, a random main memory reference takes about 100 nanoseconds. This shows that reading 10 elements from random memory locations would take roughly the same time as reading 1MB of sequential data.\nMoreover, the CPU will likely have an L1 (and maybe L2) cache. When the OS fetches an array element from the main memory to the L1 cache, it\u0026rsquo;s likely to prefetch and store the elements at the following indexes, improving the performance even further.\nNotice how we make a conscious trade-off between memory and running time when we double the array. This is fine if memory is available and cheap, which is usually the case. If not, we need a different strategy (i.e., increase the length by 25% or 50%).\nsize() Next, we will implement the size method, which returns the number of elements in the list. The way we used nextIndex in our add method, it will always be equal to the size of the list:\n@Override public int size() { return nextIndex; } remove(index) Next up, the remove method -\n@Override public E remove(int index) { /* * Specification: if the index is out of bound, then throw * IndexOutOfBoundsException. */ if (index \u0026lt; 0 || index \u0026gt;= nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } } If index is the last element in the elements array, we could decrement nextIndex by one so that the next insertion will overwrite the element at index nextIndex - 1:\n@Override public E remove(int index) { /* * Specification: if the index is out of bound, then throw * IndexOutOfBoundsException. */ if (index \u0026lt; 0 || index \u0026gt;= nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } if (index == nextIndex - 1) { nextIndex--; return elements[nextIndex]; } } Unfortunately, this implementation suffers from a memory leak. Let me explain why.\nSuppose we have a list object with 10,000 elements and would like to remove each element one by one from the end without adding any new ones. In that case, nextIndex will keep decreasing, but the references to all these removed objects will still be in the array, preventing garbage collection.\nTo prevent memory leak, we need to explicitly clear the reference by setting it to null:\n@Override public E remove(int index) { /* * Specification: if the index is out of bound, then throw * IndexOutOfBoundsException. */ if (index \u0026lt; 0 || index \u0026gt;= nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } if (index == nextIndex - 1) { nextIndex--; E elementBeingRemoved = (E) elements[index]; elements[nextIndex] = null; return elementBeingRemoved; } } To remove elements from any other position in the array, we can shift all elements starting from index one position to the left and then decrement nextIndex:\n@Override public E remove(int index) { /* * Specification: if the index is out of bound, then throw * IndexOutOfBoundsException. */ if (index \u0026lt; 0 || index \u0026gt;= nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } if (index == nextIndex - 1) { nextIndex--; E elementBeingRemoved = (E) elements[index]; elements[nextIndex] = null; return elementBeingRemoved; } E elementBeingRemoved = (E) elements[index]; nextIndex--; for (int i = index; i \u0026lt; nextIndex; i++) { elements[i] = elements[i + 1]; } elements[nextIndex] = null; return elementBeingRemoved; } We can combine these two cases:\n@Override public E remove(int index) { /* * Specification: if the index is out of bound, then throw * IndexOutOfBoundsException. */ if (index \u0026lt; 0 || index \u0026gt;= nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } E elementBeingRemoved = (E) elements[index]; nextIndex--; for (int i = index; i \u0026lt; nextIndex; i++) { elements[i] = elements[i + 1]; } elements[nextIndex] = null; return elementBeingRemoved; } We can also leverage the Data Locality property here by copying elements by blocks. We will use the same System.arraycopy method, where both our source and destination will be the same array. The JavaDoc of System.arraycopy says -\nIf the src and dest arguments refer to the same array object, then the copying is performed as if the components at positions srcPos through srcPos + length - 1 were first copied to a temporary array with length components and then the contents of the temporary array were copied into positions destPos through destPos + length - 1 of the destination array.\nTo understand how the copy within the same array will work, notice that we move the element at index index + 1 to index, index + 2 to index + 1, and then finally, the element at index nextIndex to index nextIndex - 1. This implies that we specify index + 1 as the source index when doing block copy, as that\u0026rsquo;s the first element we copy. We specify index as our destination index as that\u0026rsquo;s where the first element finally moves to. nextIndex - index will give us the number of elements that need to be copied, as shown by the image below:\nLet\u0026rsquo;s go ahead and refactor our method -\n@Override public E remove(int index) { /* * Specification: if the index is out of bound, then throw * IndexOutOfBoundsException. */ if (index \u0026lt; 0 || index \u0026gt;= nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } E elementBeingRemoved = (E) elements[index]; nextIndex--; System.arraycopy(elements, index + 1, elements, index, nextIndex - index); elements[nextIndex] = null; return elementBeingRemoved; } We can also resize and reduce the array size similar to the add method above. I leave it up as a fun exercise for the reader.\nadd(index, element) Next method is add(index, element):\npublic void add(int index, E element) { /* * Specification: if the index is out of bound, then throw * IndexOutOfBoundsException. * * Notice the difference with the index check of the * `remove` method. */ if (index \u0026lt; 0 || index \u0026gt; nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } /* * If the index == nextIndex, we can leverage the `add` * method to add the element at the end. */ if (index == nextIndex) { add(element); return; } } The initial version implements the relatively more straightforward cases - when the index is out of bounds and when we insert the element at the end of the list. To finish the implementation, we need to consider two additional cases - when we don\u0026rsquo;t have enough space and need to resize the array and where we have enough space.\nTo handle the first case, we will resize the array as we did for add. Once resized, we will copy the first index number of elements to this new array, add the element at the given index, and then copy the rest of the elements to the new array -\nTo handle the second case, we first shift all elements from the given index and then insert the new element at the index position. The code for both these cases are given below:\n@Override public void add(int index, E element) { /* * Specification: if the index is out of bound, * then throw IndexOutOfBoundsException. * * Notice the difference with the index check of the * `remove` method. */ if (index \u0026lt; 0 || index \u0026gt; nextIndex) { throw new IndexOutOfBoundsException( \u0026#34;index \u0026#34; + index + \u0026#34; is out of range\u0026#34; ); } /* * If the index == nextIndex, we can leverage the `add` * method to add the element at the end. */ if (index == nextIndex) { add(element); return; } if (nextIndex == elements.length) { Object[] copy = new Object[nextIndex * 2]; System.arraycopy(elements, 0, copy, 0, index); copy[index] = element; System.arraycopy(elements, index, copy, index + 1, nextIndex - index); elements = copy; } else { System.arraycopy(elements, index, elements, index + 1, nextIndex - index); elements[index] = element; } nextIndex++; } contains(element) This implementation is relatively straightforward. We do a linear scan through the elements array from left to right, checking for object equality to see if the given element exists in the array:\n@Override public boolean contains(Object element) { for (int i = 0; i \u0026lt; nextIndex; i++) { if (Objects.equals(elements[i], element)) { return true; } } return false; } Or we can use streams:\n@Override public boolean contains(Object element) { return Arrays.stream(elements) .limit(size()) .anyMatch(existingElement -\u0026gt; Objects.equals(existingElement, element)); } remove(element) We can leverage the existing remove(index) method to implement removal by element. To do that, we do a linear scan of our elements array, find the index of the element, and then call remove(index):\n@Override public boolean remove(Object element) { for (int i = 0; i \u0026lt; nextIndex; i++) { if (Objects.equals(elements[i], element)) { remove(i); return true; } } return false; } iterator() We will implement a simplified version of the iterator, which will not check for concurrent modification and will not allow removal via the iterator.\nWe will write a custom Iterator, which will take a snapshot of our list\u0026rsquo;s size() and then continue iterating until we all elements have been returned:\nprivate class CustomArrayListIterator implements Iterator\u0026lt;E\u0026gt; { private final int size = CustomArrayList.this.size(); private int index = 0; @Override public boolean hasNext() { return index \u0026lt; size; } @Override public E next() { return (E) elements[index++]; } } @Override public Iterator\u0026lt;E\u0026gt; iterator() { return new CustomArrayListIterator(); } When to use an array-backed list? Now that we have seen how an array-based list implementation works, when should we use them? And when should we avoid using them?\nAs a rule of thumb - I always prefer using ArrayList over other list implementations like LinkedList. In almost all cases, a linked list based-implementation will lose out to ArrayList in terms of performance. The performance boost from Data Locality combined with sequential memory block copy and Prefetching in L1 and/or L2 cache is hard to beat.\nThere is a particular scenario where LinkedList may perform better than ArrayList. When we constantly need to add and/or remove elements from the beginning of the list (or anywhere before the midpoint of the list) AND the list contains millions and millions of objects, then a LinkedList may provide better performance. Even then, I recommend performing a benchmark/load test to see if the ArrayList is the bottleneck.\nConclusion I hope you enjoyed reading the article. In future posts of the Unwinding the Abstraction series, I hope to demystify more tools and share the learnings with you all.\nThe sample implementation used in this article is available at Github.\nAcknowledgements Many thanks to Nur Bahar Yeasha for proofreading a draft version of this article and suggesting corrections and improvements.\n","permalink":"https://www.sayemahmed.com/posts/unwinding-the-abstraction-how-does-arraylist-in-java-work/","summary":"Introduction One of my all-time favourite articles is The Law of Leaky Abstractions by Joel Spolsky. In the article, Joel explains how non-trivial abstractions that make software development more manageable often break. And when they do, we need to understand how they truly work so we can fix them quickly.\nThis is the reason I value learning from first principles. Over the years, I have often applied this learning style to learn more about the tools I use regularly.","title":"Unwinding the Abstraction - How does ArrayList in Java Work?"},{"content":"Introduction Logging is an essential part of any modern Java application. Logs allow us to understand the runtime behaviour of our applications. They also help us capture the context when errors occur. Without logging debugging a production issue will often be quite tricky. Throughout my career, I have found specific logging patterns more valuable than others when on-call. And some - not so much. In this blog post, I will talk about a few of them with examples.\nContext All patterns or anti-patterns always have an associated context. In the following discussion, I assume a high-traffic web application is doing all the logging. By \u0026ldquo;high-traffic\u0026rdquo;, I mean a web application serving at least 30K requests per second.\n1. Avoiding duplicate error logs while preserving the context Consider the following code -\npublic SomeResult performSomeOperation(SomeData someData) { try { return someService.doSomething(someData); } catch (SomeCommonException ex) { log.error(\u0026#34;Error occurred. Data - {}\u0026#34;, someData, ex); throw new AnotherCommonException(\u0026#34;Some error occurred\u0026#34;); } } There are two reasons this pattern is not helpful when I am on call. First, it results in unnecessary noise in the production log. In this example, we log an error message immediately after catching the exception. But then we are throwing a new exception - AnotherCommonException. Now the client of \u0026ldquo;performSomeOperation\u0026rdquo; would need to deal with this exception -\npublic SomeResult clientOfPerformSomeOperation(SomeData someData) { try { return someService.performSomeOperation(someData); } catch (AnotherCommonException ex) { // log it? Throw a new error? Do both? } } In the worst case, each client will log an error message and rethrow the exception. As a result, we will end up with two or more log messages for a single error. If 1% of the incoming requests encounter SomeCommonException, then that would mean six hundred error logs per second being logged, three hundred of which are duplicates. That\u0026rsquo;s a lot of unnecessary error messages! On top of that, a 1% failure is often considered acceptable in a distributed application, in which case logging these \u0026ldquo;acceptable failures\u0026rdquo; might even mislead me to think that this might be the source of an active alert.\nThe second reason is that we have no link between the root cause and the follow-up exception. For a high-traffic application, the first and the second log message will be far apart in the production log. And chances of linking them together will be low. As a result, the production log will contain random exceptions without any context, which might also be a source of misdirection for me.\nThe on-call-friendlier version of the above example would be -\npublic SomeResult performSomeOperation(SomeData someData) { try { return someService.doSomething(someData); } catch (SomeCommonException ex) { throw new AnotherCommonException( \u0026#34;Error occurred. Data - {}\u0026#34; + someData, ex ); } } This logging does not have the above problems. It does not create duplicate log messages. It also preserves the original error context. Identifying and filtering them out from the log is also relatively easy.\nHaving precisely one log message per error has other advantages. It makes it easy to count the exact number of errors at a particular time. If the exception is occurring due to a timed-out API call, then searching the log for ERROR levels within a, say, 30-minute time window will return the exact number of failed API calls within the period.\n2. Logging \u0026ldquo;acceptable failures\u0026rdquo; with WARN level Consider the following API call -\npublic String get() { try { return restTemplate.getForEntity( \u0026#34;https://httpstat.us/500\u0026#34;, String.class ); } catch (Exception ex) { log.error(\u0026#34;Error occurred\u0026#34;, ex); return \u0026#34;A default response\u0026#34;; } } Making remote API calls 100% reliable is practically impossible. And so it\u0026rsquo;s expected that a certain percentage of this call will fail. For our high-traffic web application, a 0.5% failure rate here would mean 150 errors per second. Logging each one as an error would thus generate high-volume noise in the production log.\nRather than logging it as an error, I would rather recommend logging it as a WARN -\npublic String get() { try { return restTemplate.getForEntity( \u0026#34;https://httpstat.us/500\u0026#34;, String.class ); } catch (Exception ex) { log.warn( \u0026#34;API call failure. Context data should also be logged\u0026#34;, ex ); return \u0026#34;A default response\u0026#34;; } } Logging these failures as WARN still tracks our API failures while at the same time making it easy to filter them out.\nThis example also demonstrates one of my logging heuristics - I always consider an ERROR log worthy of keeping me awake at night. If this is not the case, I will not log it as an ERROR.\n3. Avoid logging validation failures as errors Consider the following code:\n@RestController public class SomeController { @PostMapping public ResponseEntity\u0026lt;?\u0026gt; createOrder(OrderDTO dto) { var validationResult = validateDto(dto); if (validationResult.hasError()) { log.error(\u0026#34;Validation error: {}\u0026#34;, validationResult.toError()); return ResponseEntity.badRequest() .build(); } // create order logic } } Logging a validation error as an error in the log is 100% noise. Validation errors represent an incomplete request; the application cannot process the request in its current form. And so, logging these requests as errors only pollute the log. I recommend removing this logging altogether.\nThere is a rare exception to this. Often, clients would ask for a log of a particular request to debug their code. For example, if this API serves mobile apps and there is a logical bug in the validation on the mobile app, then this error logging might be helpful. In that case, we might consider keeping this log but with a different level -\n@RestController public class SomeController { @PostMapping public ResponseEntity\u0026lt;?\u0026gt; createOrder(OrderDTO dto) { var validationResult = validateDto(dto); if (validationResult.hasError()) { log.info(\u0026#34;Validation error: {}\u0026#34;, validationResult.toError()); return ResponseEntity.badRequest() .build(); } // create order logic } } This logging might be acceptable if the web application receives a low traffic volume. For a high-traffic website, this would, however, require a considerable amount of log storage. In such cases, it is always better to rely on an observability tool which can perform after-the-fact sampling (sampling 1% of the requests that generate 400).\n","permalink":"https://www.sayemahmed.com/posts/debugging-friendly-logging-patterns/","summary":"Introduction Logging is an essential part of any modern Java application. Logs allow us to understand the runtime behaviour of our applications. They also help us capture the context when errors occur. Without logging debugging a production issue will often be quite tricky. Throughout my career, I have found specific logging patterns more valuable than others when on-call. And some - not so much. In this blog post, I will talk about a few of them with examples.","title":"On-call-friendly Java Logging Patterns"},{"content":"Thank you very much for reading my blog.\nMy name is MD Sayem Ahmed. I am a Software Engineer by profession and currently living and working in Berlin, Germany.\nI love working with complex distributed systems and building high-performance web applications. I am most experienced in Java-based technologies like Spring, JPA, Servlets, JSP, and related technologies, but I don\u0026rsquo;t mind working with other languages and tools if needed.\nHere is a short list of my online profiles where you can find more information about me and my work -\nLinkedIn StackOverflow Github DZone JavaCodeGeeks Scrum Alliance Drop me an email here if you want to say hi :-) .\nDisclaimer: The views and opinions expressed here are my own only and in no way represent the views, positions or opinions – expressed or implied – of my employer (present and past).\n","permalink":"https://www.sayemahmed.com/about-me/","summary":"Thank you very much for reading my blog.\nMy name is MD Sayem Ahmed. I am a Software Engineer by profession and currently living and working in Berlin, Germany.\nI love working with complex distributed systems and building high-performance web applications. I am most experienced in Java-based technologies like Spring, JPA, Servlets, JSP, and related technologies, but I don\u0026rsquo;t mind working with other languages and tools if needed.\nHere is a short list of my online profiles where you can find more information about me and my work -","title":"About Me"},{"content":"Introduction Recently I have been hearing about observability more and more. The promise that an observable system can help us to debug and identify performance and reliability issues in a microservice architecture sounded quite good to me. Hence I decided to read up and learn more on this topic. In this blog post I will try to summarise what I have learned about observability so far.\nWhat is Observability? Observability is a term or a concept that has its root in Physics, mainly in Control Theory. According to Wikipedia -\nObservability is a measure of how well internal states of a system can be inferred from knowledge of its external outputs.\n\u0026hellip; A system is said to be observable if, for any possible evolution of state and control vectors, the current state can be estimated using only the information from outputs (physically, this generally corresponds to information obtained by sensors). In other words, one can determine the behavior of the entire system from the system\u0026rsquo;s outputs. On the other hand, if the system is not observable, there are state trajectories that are not distinguishable by only measuring the outputs.\nExtending the same concept to a software system, we can say -\nA software system is observable if we can ask new questions from the outside to understand what is going on on the inside, all without deploying new code.\nSo in effect, observability is a measure of how well we can make sense of what is going on with our application by asking arbitrary questions (the unknown-unknowns) about the system, without having to know the questions in advance. The more observable our systems are, the more arbitrary questions we are able to ask. Used effectively, it can greatly improve our application quality and reliability by making it relatively easy to debug and identify potential performance and reliability issues in production.\nWhy should I care about Observability? Because software is becoming more and more complex than what it used to be, making it more difficult to predict most of the production issues in advance.\nConsider a regular monolithic application. In such applications the entire codebase is in one place, making it possible to browse through different use cases end-to-end and anticipate most (if not all) of the production issues in advance. Once the problematic areas have been identified we augment the application code to collect and report various metrics, visualise these metrics in dashboards, and create alerts. Combining application logs with with these collected metrics was often enough to debug most of the performance and reliability issues in production. If we could also throw in distributed tracing to the mix, then our chances of finding and quickly fixing these issues would increase even further.\nContrast this with the current trend in the software world. Nowadays we see a clear preference among companies to decompose large monolithic applications into smaller-sized microservices in order to achieve greater business agility. As a result, systems are becoming more and more distributed. Small and independent teams are working on different distributed systems in parallel whose code bases are separate. What used to be functions invocations before have now been converted to network calls between remote applications. With the adoption of DevOps practices releases are becoming more frequent, reducing the time needed to release features to production once they are ready. All of these are resulting in more moving parts in a system which are changing frequently at their own pace, making it difficult to predict how an application will behave in production. Often times, questions like “will the release of this new features in application X interfere with the existing features in application a? What about application b? Or c?….” can be answered only after we release application X in production. As a direct consequence of adopting a microservice-oriented architecture, debugging gets more difficult than a monolithic system.\nThis is where the concept of observability is particularly useful. Being able to ask arbitrary questions about our entire system without having to know them in advance can greatly reduce the burden of debugging and identifying performance and reliability issues in a microservice architecture.\nThe 3 pillars of Observability Metrics, Logs, and Distributed Traces are often called the 3 pillars of observability because these are the tools we have been traditionally using to make sense of our system. Most of us already familiar with these concepts and related tools, so we are not going to dive deep into them in this article. Instead, we will try to understand why these 3 pillars are not enough to create an observable system.\nMetrics Metrics are numerical measurements taken over intervals of time. We use metrics to to measure response times of requests, to count the number requests that failed to get a valid response etc. For a long time metrics have been the standard way to monitor the overall health of an application - number of live instances, current memory consumption, cpu usage, response times, query execution time etc. They are also being used to trigger alerts in case of emergencies like instances going down, low memory, high cpu usage etc. All in all, very useful tool.\nHowever, traditional metrics-based tools are not enough to create an observable system. One of the primary reasons for this is that any tools that are metric-based can deal with only low-cardinality dimensions. Things like user ids, purchase ids, shopping cart ids - any data that have high-cardinality are not collected with these tools as otherwise the cost would blow up. Also, in order to keep the associated costs low, metrics are aggregated on the client-side and then stored in their aggregated form, losing granularity even further. Without high-cardinality data it is difficult to investigate and debug issues in a microservice architecture. As a result any questions that are answered by a metric-based tool have to be pre-defined so that we can collect targeted metrics to answer them. This is an antithesis to the premise of observability as observability requires being able to ask arbitrary questions about a system without knowing them in advance. Without high-cardinality data, this is not possible.\nAnother downside is that the metrics that are collected are not tied to their source request which triggered them. In a microsevice-oriented architecture a single user request can hit many different services, query different databases or caches, send messages to queues or kafka topics, or can interact with any combination of these. We can collect metrics from each of these sources, but once collected we can never link them back together. This makes it difficult to answer questions like why do this particular group of users see a high response times of 10 seconds while our metrics dashboard is showing a p99 of 1 seconds?\nLogs Logs are a useful tool which help us debug issues by providing us context-dependent messages and stack traces. However, they cannot be used effectively to create an observable system.\nOne of the primary downsides of using logging to create an observable system is the associated cost. Systems that use logging to improve observability becomes too expensive to maintain. This is how Ben Sigelman, co-founder of Lightstep, explains the problem in one of his articles written on the Lightstep blog (I highly recommend to give the entire article a thorough read) -\nIf we want to use logs to account for individual transactions (like we used to in the days of a monolithic web server\u0026rsquo;s request logs), we would need to pay for the following:\nApplication transaction rate * all microservices * cost of network and storage * weeks of data retention = way, way too much $$$$ Logging systems can\u0026rsquo;t afford to store data about every transaction anymore because the cost of those transactional logs is proportional to the number of microservices touched by an average transaction.\nAnother downside is that In order to answer any arbitrary questions about our system we would have to log quite aggressively. Since traditional logging libraries cannot dynamically sample logs, logging excessively could adversely affect the performance of the application as a whole.\nDistributed Tracing This is how OpenTracing, a Cloud Native Computing Foundation project, defines Distributed Tracing -\nDistributed tracing, also called distributed request tracing, is a method used to profile and monitor applications, especially those built using a microservices architecture. Distributed tracing helps pinpoint where failures occur and what causes poor performance.\nDistributed Tracing has its use in building an observable system. After all, they are the threads with which we can connect an end-to-end request in a microservice architecture. However, they come with a few challenges on their own.\nThe first challenge is choosing a right sampling strategy. Traditionally distributed tracing tools have been making the decision of whether to sample a request or not at the very beginning, when a request enters the infrastructure for the first time from outside. This results in a sampling strategy that is either too aggressive and collect too much data which are expensive to store and analyse, or too relaxed and does not collect enough data to help us with observability.\nThe second challenge is the UI with which we analyse the trace data. Tracing tools usually come with a UI component which display all the traces in what is called a trace view. In a system with hundreds of services where a typical request touches 20 or 30 of them, the trace view becomes too complex for a human to analyse without any automated support. In addition, spans, which are treated as units of work by the tracing systems and responsible for capturing trace data from services, are too low level to be used for debugging purposes. Cindy Sridharan wrote an excellent article on this topic where she explains the problem in a much better way -\nAdmittedly, some tracing systems provide condensed traceviews when the number of spans in a trace are so exceedingly large that they cannot be displayed in a single visualization. Yet, the amount of information being encapsulated even in such pared down views still squarely puts the onus on the engineers to sift through all the data the traceview exposes and narrow down the set of culprit services. This is an endeavor machines are truly faster, more repeatable and less error-prone than humans at accomplishing.\n\u0026hellip; The fundamental problem with the traceview is that a span is too low-level a primitive for both latency and “root cause” analysis. It’s akin to looking at individual CPU instructions to debug an exception when a much higher level entity like a backtrace would benefit day-to-day engineers the most.\nFurthermore, I’d argue that what is ideally required isn’t the entire picture of what happened during the lifecycle of a request that modern day traces depict. What is instead required is some form of higher level abstraction of what went wrong (analogous to the backtrace) along with some context. Instead of seeing an entire trace, what I really want to be seeing is a portion of the trace where something interesting or unusual is happening. Currently, this process is entirely manual: given a trace, an engineer is required to find relevant spans to spot anything interesting. Humans eyeballing spans in individual traces in the hopes of finding suspicious behavior simply isn’t scalable, especially when they have to deal with the cognitive overhead of making sense of all the metadata encoded in all the various spans like the span ID, the RPC method name, the duration of the span, logs, tags and so forth.\nI highly recommend you to give the article a thorough read.\nWhat does an ideal Observability tool look like? Charity Majors, co-founder of HoneyComb, wrote an excellent article on the HoneyComb blog where she mentions the criteria that a tool must fulfil in order to deliver observability -\nArbitrarily-wide structured raw events Context persisted through the execution path Without indexes or schemas High-cardinality, high-dimensionality Ordered dimensions for traceability Client-side dynamic sampling An exploratory visual interface that lets you slice and dice and combine dimensions In close to real-time She then goes on to explain the reasoning behind her choices, all of which I fully agree with. I highly recommend giving the article a thorough read.\nTrying out an existing Observability tool - HoneyComb In the same article that I have mentioned just now, Charity mentions how HoneyComb was built to deliver on these promises. Hence I decided to give it a try by checking out their live play scenarios.\nIn the Play with Tracing and BubbleUp scenario I followed the step by step guide to identify some outlier requests which were taking longer than the rest. By the end of the demo I was able to nail the problem down to the individual user who was experiencing the slower response times. I could definitely see how this technique could help me to debug performance issues in production which are affecting a portion of the users but are not visible in my pre-defined metrics dashboard.\nNext I tried out the Play with Events scenario which contains data about an actual production incident that HoneyComb faced back in 2018. Using the step by step guide as before I was able to identify the failed database that was the root of the issue.\nI noticed the following aspects of the tool -\nHigh-cardinality data: In the first scenario I was able to link the response time with an individual user, and then link the slower response time with the individual query that was being executed. Without high-cardinality this would have been impossible. In the absence of high cardinality data I could at best try to guess the issue and add sporadic log statements here and there, but I would still have to rely on luck to give me a break. Debugging should not be tied to luck. Metrics are also tied to requests/traces: All response times were tied with each individual trace, thus making it easy to identify requests which were slow. Wide events: The trace events contained a lot of data, including even the database query that was executed by the affected user! Without this query it would have been difficult to nail it down to the database performance problem. Dynamic dashboards: all the dashboards that are being generated are fully dynamic, and it\u0026rsquo;s possible to create dashboards per dimension! At this point I was curious to know the strategy HoneyComb uses to decide which requests to sample. I searched in the doc and found the section about Dynamic Sampling, where it\u0026rsquo;s mentioned how it\u0026rsquo;s possible to make the sampling decision based on whether an HTTP request encounters an error -\nFor example: when recording HTTP events, we may care about seeing every server error but need less resolution when looking at successful requests. We can then set the sample rate for successful requests to 100 (storing one in a hundred successful events). We include the sample rate along with each event—100 for successful events and 1 for error events.\nHence with HoneyComb it is possible to delay the sampling decision once the request has been fully executed. This strategy is very handy and can be used to sample aggressively for failed/problematic requests and thus making it easy to debug them, while at the same time performing a relaxed sampling for the successful requests and thus helping us to keep the data volume low.\nOne other thing that I noticed - in order to identify which requests are slow, we first need to define what a slow request looks like. For some applications it may be perfectly acceptable if a request completes within 4 seconds, while for some other type of applications it might be too slow. Since SLI/SLO/SLAs are gaining more and more popularity in our industry, it would make sense to use SLOs to define these criteria, and then create sampling strategies based on this definition. If a request fails our SLO, we can always decide to sample and store the request so that we can later debug why it failed. If it is successful, we can adopt a more relaxed sampling rate.\nAll in all, HoneyComb has left quite a good impression on me. Indeed it\u0026rsquo;s an excellent tool!\nAre Metric-based monitoring tools going to be obsolete? I don\u0026rsquo;t think so. Metrics-based monitoring tools are still the best choice when we want to answer any pre-defined questions about our system (also called known-unknowns) -\nHow many application instances are live at the moment? What is the amount of memory being consumed by the applications? What is the CPU usage etc. Observability tools, on the other hand, are best at answering the unknown-unknowns, things like -\nWhy does this user sees a response time of 4 seconds? Why are the database queries hitting the database instances in region X take more than 5 seconds to complete etc. Any ideal observable system would combine them both.\nConclusion I am still at the very early stage of my observability journey, and still learning the concepts and the tools used in this field. However, I am already convinced that in a distributed system architecture observability practices are invaluable and can help us improve the quality and the reliability of our applications by a great deal. I intend to apply these practices in my day to day work and as I learn more I will definitely try to share my learnings in my blog (given time permits)!\nAcknowledgements These are the resources which helped me learned about what observability truly is and how to build an observable system -\nDefinition of Observability by Charity Majors Observability — A 3-Year Retrospective - Charity Majors Three Pillars with Zero Answers - Towards a New Scorecard for Observability - Ben Sigelman So You Want To Build An Observability Tool… - Charity Majors Distributed Systems Observability - Cindy Sridharan Distributed Tracing — we’ve been doing it wrong - Cindy Sridharan ","permalink":"https://www.sayemahmed.com/posts/how-to-build-observable-system-an-introduction-to-observability/","summary":"Introduction Recently I have been hearing about observability more and more. The promise that an observable system can help us to debug and identify performance and reliability issues in a microservice architecture sounded quite good to me. Hence I decided to read up and learn more on this topic. In this blog post I will try to summarise what I have learned about observability so far.\nWhat is Observability? Observability is a term or a concept that has its root in Physics, mainly in Control Theory.","title":"How to Build Observable Systems - An Introduction to Observability"},{"content":"Executable Specifications are tests that can also serve as design specifications. They enable technical and business teams to get on the same page by enabling the use of a common language (in DDD-world this is also known as Ubiquitous Language). They function as documentations for the future maintainers of the code. In this article we will see an opinionated way of writing automated tests which could also function as Executable Specifications.\nLet\u0026rsquo;s start with an example. Suppose we are creating an accounting system for a business. The system will allow its users to record incomes and expenses into different accounts. Before users can start recording incomes and expenses, they should be able to add new accounts into the system. Suppose that the specification for the \u0026ldquo;Add New Account\u0026rdquo; use case looks like below -\nScenario 1 Given account does not exist When user adds a new account Then added account has the given name Then added account has the given initial balance Then added account has user\u0026rsquo;s id\nScenario 2 Given account does not exist When user adds a new account with negative initial balance Then add new account fails\nScenario 3 Given account with the same name exists When user adds a new account Then add new account fails\nIn order to create a new account the user needs to enter an account name and an initial balance into the system. The system will then create the account if no account with the given name already exists and the given initial balance is positive.\nWe will first write down a test which will capture the first \u0026ldquo;Given-When-Then\u0026rdquo; part of the first scenario. This is how it looks like -\nclass AddNewAccountTest { @Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { } } The @DisplayName annotation was introduced in JUnit 5. It assigns a human-readable name to a test. This is the label that we would see when we execute this test e.g., in an IDE like IntelliJ IDEA.\nWe will now create a class which will be responsible for adding the account -\nclass AddNewAccountService { void addNewAccount(String accountName) { } } The class defines a single method which accepts the name of an account and will be responsible for creating it i.e., saving it to a persistent data store. Since we decided to call this class AddNewAccountService, we will also rename our test to AddNewAccountServiceTest to follow the naming convention used in the JUnit world.\nWe can now proceed with writing our test -\nclass AddNewAccountServiceTest { @Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { AddNewAccountService accountService = new AddNewAccountService(); accountService.addNewAccount(\u0026#34;test account\u0026#34;); // What to test? } } What should we test/verify to ensure that the scenario is properly implemented? If we read our specification again, it is clear that we want to create an \u0026ldquo;Account\u0026rdquo; with a user-given name, hence this is what we should try to test here. In order to do this, we will have to first create a class which will represent an Account -\n@AllArgsConstructor class Account { private String name; } The Account class has only one property called name. It will have other fields like user id and balance, but we are not testing those at the moment, hence we will not add them to the class right away.\nNow that we have created the Account class, how do we save it, and more importantly, how do we test that the account being saved has the user-given name? There are many approaches to do this, and my preferred one is to define an interface which will encapsulate this saving action. Let\u0026rsquo;s go ahead and create it -\ninterface SaveAccountPort { void saveAccount(Account account); } The AddNewAccountService will be injected with an implementation of this interface via constructor injection -\n@RequiredArgsConstructor class AddNewAccountService { private final SaveAccountPort saveAccountPort; void addNewAccount(String accountName) { } } For testing purposes we will create a mock implementation with the help of Mockito so that we don\u0026rsquo;t have to worry about the actual implementation details -\n@ExtendWith(MockitoExtension.class) class AddNewAccountServiceTest { @Mock private SaveAccountPort saveAccountPort; @Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); accountService.addNewAccount(\u0026#34;test account\u0026#34;); // What to test? } } Our test setup is now complete. We now expect our method under test, the addNewAccount method of the AddNewAccountService class, to invoke the saveAccount method of the SaveAccountPort, with an Account object whose name is set to the one passed to the method. Let\u0026rsquo;s codify this in our test -\n@ExtendWith(MockitoExtension.class) class AddNewAccountServiceTest { @Mock private SaveAccountPort saveAccountPort; @Captor private ArgumentCaptor\u0026lt;Account\u0026gt; accountArgumentCaptor; @Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); accountService.addNewAccount(\u0026#34;test account\u0026#34;); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); BDDAssertions.then(accountArgumentCaptor.getValue().getName()).isEqualTo(\u0026#34;test account\u0026#34;); } } The line below -\nBDDMockito.then(saveAccountPort) .should() .saveAccount(accountArgumentCaptor.capture()); verifies that the saveAccount method of the SaveAccountPort is invoked once the method under test is invoked. We also capture the account argument that is passed to the saveAccount method with our argument captor. The next line -\nBDDAssertions.then(accountArgumentCaptor.getValue().getName()) .isEqualTo(\u0026#34;test account\u0026#34;); then verifies that the captured account argument has the same name as the one that was passed in the test.\nIn order to make this test pass, the minimal code that is needed in our method under test is as follows -\n@RequiredArgsConstructor class AddNewAccountService { private final SaveAccountPort saveAccountPort; void addNewAccount(String accountName) { saveAccountPort.saveAccount(new Account(accountName)); } } With that, our test starts to pass!\nLet\u0026rsquo;s move on to the second \u0026ldquo;Then\u0026rdquo; part of the first scenario, which says -\nThen added account has the given initial balance Let\u0026rsquo;s write another test which will verify this part -\n@Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account Then added account has the given initial balance\u0026#34;) void accountAddedWithGivenInitialBalance() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); accountService.addNewAccount(\u0026#34;test account\u0026#34;, \u0026#34;56.0\u0026#34;); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); BDDAssertions.then(accountArgumentCaptor.getValue().getBalance()) .isEqualTo(new BigDecimal(\u0026#34;56.0\u0026#34;)); } We have modified our addNewAccount method to accept the initial balance as the second argument. We have also added a new field, called balance, in our Account object which is able to store the account balance -\n@AllArgsConstructor @Getter class Account { private String name; private BigDecimal balance; } Since we have changed the signature of the addNewAccount method, we will also have to modify our first test -\n@Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); accountService.addNewAccount(\u0026#34;test account\u0026#34;, \u0026#34;1\u0026#34;); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); BDDAssertions.then(accountArgumentCaptor.getValue().getName()).isEqualTo(\u0026#34;test account\u0026#34;); } If we run our new test now it will fail as we haven\u0026rsquo;t implemented the functionality yet. Let\u0026rsquo;s do that now -\nvoid addNewAccount(String accountName, String initialBalance) { saveAccountPort.saveAccount(new Account(accountName, new BigDecimal(initialBalance))); } Both of our tests should pass now.\nAs we already have a couple of tests in place, it\u0026rsquo;s time to take a look at our implementation and see if we can make it better. Since our AddNewAccountService is as simple as it can be, we don\u0026rsquo;t have to do anything there. As for our tests, we could eliminate the duplication in our test setup code - both tests are instantiating an instance of the AddNewAccountService and invoking the addNewAccount method on it in the same way. Whether to remove or keep this duplication depends on our style of writing tests - if we want to make each test as independent as possible, then let\u0026rsquo;s leave them as they are. If we, however, are fine with having a common test setup code, then we could change the tests as follows -\n@ExtendWith(MockitoExtension.class) @DisplayName(\u0026#34;Given account does not exist When user adds a new account\u0026#34;) class AddNewAccountServiceTest { private static final String ACCOUNT_NAME = \u0026#34;test account\u0026#34;; private static final String INITIAL_BALANCE = \u0026#34;56.0\u0026#34;; @Mock private SaveAccountPort saveAccountPort; @Captor private ArgumentCaptor\u0026lt;Account\u0026gt; accountArgumentCaptor; @BeforeEach void setup() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); accountService.addNewAccount(ACCOUNT_NAME, INITIAL_BALANCE); } @Test @DisplayName(\u0026#34;Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); BDDAssertions.then(accountArgumentCaptor.getValue().getName()).isEqualTo(ACCOUNT_NAME); } @Test @DisplayName(\u0026#34;Then added account has the given initial balance\u0026#34;) void accountAddedWithGivenInitialBalance() { BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); BDDAssertions.then(accountArgumentCaptor.getValue().getBalance()) .isEqualTo(new BigDecimal(INITIAL_BALANCE)); } } Notice that we have also extracted the common part of the @DisplayName and put this on top of the test class. If we are not comfortable doing this, we could also leave them as they are.\nSince we have more than one passing tests, from now on every time we make a failing test pass we will stop for a moment, take a look at our implementation, and will try to improve it. To summarise, our implementation process will now consist of the following steps -\nAdd a failing test while making sure existing tests keep passing Make the failing test pass Pause for a moment and try to improve the implementation (both the code and the tests) Moving on, we now need to store user ids with the created account. Following our method we will first write a failing test to capture this and then add the minimal amount of code needed to make the failing test pass. This is how the implementation looks like once the failing test starts to pass -\n@ExtendWith(MockitoExtension.class) @DisplayName(\u0026#34;Given account does not exist When user adds a new account\u0026#34;) class AddNewAccountServiceTest { private static final String ACCOUNT_NAME = \u0026#34;test account\u0026#34;; private static final String INITIAL_BALANCE = \u0026#34;56.0\u0026#34;; private static final String USER_ID = \u0026#34;some id\u0026#34;; private Account savedAccount; @BeforeEach void setup() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); accountService.addNewAccount(ACCOUNT_NAME, INITIAL_BALANCE, USER_ID); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); savedAccount = accountArgumentCaptor.getValue(); } // Other tests..... @Test @DisplayName(\u0026#34;Then added account has user\u0026#39;s id\u0026#34;) void accountAddedWithUsersId() { BDDAssertions.then(accountArgumentCaptor.getValue().getUserId()).isEqualTo(USER_ID); } } @RequiredArgsConstructor class AddNewAccountService { private final SaveAccountPort saveAccountPort; void addNewAccount(String accountName, String initialBalance, String userId) { saveAccountPort.saveAccount(new Account(accountName, new BigDecimal(initialBalance), userId)); } } @AllArgsConstructor @Getter class Account { private String name; private BigDecimal balance; private String userId; } Since all the tests are now passing, it\u0026rsquo;s improvement time! Notice that the addNewAccount method accepts three argument already. As we introduce more and more account properties its argument list will also start to increase. We could introduce a parameter object to avoid that -\n@RequiredArgsConstructor class AddNewAccountService { private final SaveAccountPort saveAccountPort; void addNewAccount(AddNewAccountCommand command) { saveAccountPort.saveAccount( new Account( command.getAccountName(), new BigDecimal(command.getInitialBalance()), command.getUserId() ) ); } @Builder @Getter static class AddNewAccountCommand { private final String userId; private final String accountName; private final String initialBalance; } } @ExtendWith(MockitoExtension.class) @DisplayName(\u0026#34;Given account does not exist When user adds a new account\u0026#34;) class AddNewAccountServiceTest { // Fields..... @BeforeEach void setup() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); AddNewAccountCommand command = AddNewAccountCommand.builder() .accountName(ACCOUNT_NAME) .initialBalance(INITIAL_BALANCE) .userId(USER_ID) .build(); accountService.addNewAccount(command); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); savedAccount = accountArgumentCaptor.getValue(); } // Remaining Tests..... } If I now run the tests in my IDEA, I see all tests are passing, and they all have readable names.\nRight, let\u0026rsquo;s move on the the second scenario of our use case, which is a validation rule -\nGiven account does not exist When user adds a new account with negative initial balance Then add new account fails\nLet\u0026rsquo;s write a new test which tries to capture this -\n@ExtendWith(MockitoExtension.class) @DisplayName(\u0026#34;Given account does not exist When user adds a new account\u0026#34;) class AddNewAccountServiceTest { // Other tests @Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account with negative initial balance Then add new account fails\u0026#34;) void addNewAccountFailsWithNegativeInitialBalance() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); AddNewAccountCommand command = AddNewAccountCommand.builder().initialBalance(\u0026#34;-56.0\u0026#34;).build(); accountService.addNewAccount(command); BDDMockito.then(saveAccountPort).shouldHaveNoInteractions(); } } There are several ways we can implement validations in our service. We could throw an exception detailing the validation failures, or we could return an error object which would contain the error details. For this example we will throw exceptions if validation fails -\n@Test @DisplayName(\u0026#34;Given account does not exist When user adds a new account with negative initial balance Then add new account fails\u0026#34;) void addNewAccountFailsWithNegativeInitialBalance() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); AddNewAccountCommand command = AddNewAccountCommand.builder().initialBalance(\u0026#34;-56.0\u0026#34;).build(); assertThatExceptionOfType(IllegalArgumentException.class) .isThrownBy(() -\u0026gt; accountService.addNewAccount(command)); BDDMockito.then(saveAccountPort).shouldHaveNoInteractions(); } This test verifies that an exception is thrown when the addNewAccount method is invoked with a negative balance. It also ensures that in such cases our code does not invoke any method of the SaveAccountPort. Before we can start modifying our service to make this test pass, we have to refactor our test setup code a bit. This is because during one of our previous refactoring we moved our common test setup code into a single method which now runs before each test -\n@BeforeEach void setup() { AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); AddNewAccountCommand command = AddNewAccountCommand.builder() .accountName(ACCOUNT_NAME) .initialBalance(INITIAL_BALANCE) .userId(USER_ID) .build(); accountService.addNewAccount(command); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); savedAccount = accountArgumentCaptor.getValue(); } This setup code is now in direct conflict with the new test that we\u0026rsquo;ve just added - before each test it will always invoke the addNewAccount method with a valid command object, resulting in an invocation of the saveAccount method of the SaveAccountPort, causing our new test to fail.\nIn order to fix this, we will create a nested class within our test class where we will move our existing setup code and the passing tests -\n@ExtendWith(MockitoExtension.class) @DisplayName(\u0026#34;Given account does not exist\u0026#34;) class AddNewAccountServiceTest { @Mock private SaveAccountPort saveAccountPort; private AddNewAccountService accountService; @BeforeEach void setUp() { accountService = new AddNewAccountService(saveAccountPort); } @Nested @DisplayName(\u0026#34;When user adds a new account\u0026#34;) class WhenUserAddsANewAccount { private static final String ACCOUNT_NAME = \u0026#34;test account\u0026#34;; private static final String INITIAL_BALANCE = \u0026#34;56.0\u0026#34;; private static final String USER_ID = \u0026#34;some id\u0026#34;; private Account savedAccount; @Captor private ArgumentCaptor\u0026lt;Account\u0026gt; accountArgumentCaptor; @BeforeEach void setUp() { AddNewAccountCommand command = AddNewAccountCommand.builder() .accountName(ACCOUNT_NAME) .initialBalance(INITIAL_BALANCE) .userId(USER_ID) .build(); accountService.addNewAccount(command); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); savedAccount = accountArgumentCaptor.getValue(); } @Test @DisplayName(\u0026#34;Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { BDDAssertions.then(savedAccount.getName()).isEqualTo(ACCOUNT_NAME); } @Test @DisplayName(\u0026#34;Then added account has the given initial balance\u0026#34;) void accountAddedWithGivenInitialBalance() { BDDAssertions.then(savedAccount.getBalance()).isEqualTo(new BigDecimal(INITIAL_BALANCE)); } @Test @DisplayName(\u0026#34;Then added account has user\u0026#39;s id\u0026#34;) void accountAddedWithUsersId() { BDDAssertions.then(accountArgumentCaptor.getValue().getUserId()).isEqualTo(USER_ID); } } @Test @DisplayName(\u0026#34;When user adds a new account with negative initial balance Then add new account fails\u0026#34;) void addNewAccountFailsWithNegativeInitialBalance() { AddNewAccountCommand command = AddNewAccountCommand.builder() .initialBalance(\u0026#34;-56.0\u0026#34;) .build(); assertThatExceptionOfType(IllegalArgumentException.class) .isThrownBy(() -\u0026gt; accountService.addNewAccount(command)); BDDMockito.then(saveAccountPort).shouldHaveNoInteractions(); } } Here are the refactoring steps that we took -\nWe created an inner class and then marked the inner class with JUnit 5\u0026rsquo;s @Nested annotation. We broke down the @DisplayName label of the outermost test class and moved the \u0026ldquo;When user adds a new account\u0026rdquo; part to the newly introduced inner class. The reason we did this is because this inner class will contain the group of tests that will verify/validate behaviours related to a valid account creation scenario. We moved related setup code and fields/constants into this inner class. We have removed the \u0026ldquo;Given account does not exist\u0026rdquo; part from our new test. This is because the @DisplayName on the outermost test class already includes this, hence no point including it here again. When we run the tests now the When user adds a new account with negative initial balance Then add new account fails test fails.\nLet\u0026rsquo;s modify our service now to make the failing test pass -\nvoid addNewAccount(AddNewAccountCommand command) { BigDecimal initialBalance = new BigDecimal(command.getInitialBalance()); if (initialBalance.compareTo(BigDecimal.ZERO) \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;Initial balance of an account cannot be negative\u0026#34;); } saveAccountPort.saveAccount( new Account( command.getAccountName(), initialBalance, command.getUserId() ) ); } With that all of our tests start passing again. Next step is to look for ways to improve the existing implementation if possible. If not, then we will move on to the implementation of the final scenario which is also a validation rule -\nGiven account with the same name exists When user adds a new account Then add new account fails\nAs always, let\u0026rsquo;s write a test to capture this -\n@Test @DisplayName(\u0026#34;Given account with the same name exists When user adds a new account Then add new account fails\u0026#34;) void addNewAccountFailsForDuplicateAccounts() { AddNewAccountCommand command = AddNewAccountCommand.builder() .accountName(\u0026#34;existing name\u0026#34;) .build(); AddNewAccountService accountService = new AddNewAccountService(saveAccountPort); assertThatExceptionOfType(IllegalArgumentException.class) .isThrownBy(() -\u0026gt; accountService.addNewAccount(command)); BDDMockito.then(saveAccountPort).shouldHaveNoInteractions(); } First thing we have to figure out now is to how to find an existing account. Since this will involve querying our persistent data store, we will introduce an interface -\npublic interface FindAccountPort { Account findAccountByName(String accountName); } and inject it into our AddNewAccountService -\n@RequiredArgsConstructor class AddNewAccountService { private final SaveAccountPort saveAccountPort; private final FindAccountPort findAccountPort; // Rest of the code } and modify our test -\n@Test @DisplayName(\u0026#34;Given account with the same name exists When user adds a new account Then add new account fails\u0026#34;) void addNewAccountFailsForDuplicateAccounts() { String existingAccountName = \u0026#34;existing name\u0026#34;; AddNewAccountCommand command = AddNewAccountCommand.builder() .initialBalance(\u0026#34;0\u0026#34;) .accountName(existingAccountName) .build(); given(findAccountPort.findAccountByName(existingAccountName)).willReturn(mock(Account.class)); AddNewAccountService accountService = new AddNewAccountService(saveAccountPort, findAccountPort); assertThatExceptionOfType(IllegalArgumentException.class) .isThrownBy(() -\u0026gt; accountService.addNewAccount(command)); BDDMockito.then(saveAccountPort).shouldHaveNoInteractions(); } The last change to our AddNewAccountService will also require changes to our existing tests, mainly the place where we were instantiating an instance of that class. We will, however, change a bit more than that -\n@ExtendWith(MockitoExtension.class) class AddNewAccountServiceTest { @Mock private SaveAccountPort saveAccountPort; @Mock private FindAccountPort findAccountPort; @Nested @DisplayName(\u0026#34;Given account does not exist\u0026#34;) class AccountDoesNotExist { private AddNewAccountService accountService; @BeforeEach void setUp() { accountService = new AddNewAccountService(saveAccountPort, findAccountPort); } @Nested @DisplayName(\u0026#34;When user adds a new account\u0026#34;) class WhenUserAddsANewAccount { private static final String ACCOUNT_NAME = \u0026#34;test account\u0026#34;; private static final String INITIAL_BALANCE = \u0026#34;56.0\u0026#34;; private static final String USER_ID = \u0026#34;some id\u0026#34;; private Account savedAccount; @Captor private ArgumentCaptor\u0026lt;Account\u0026gt; accountArgumentCaptor; @BeforeEach void setUp() { AddNewAccountCommand command = AddNewAccountCommand.builder() .accountName(ACCOUNT_NAME) .initialBalance(INITIAL_BALANCE) .userId(USER_ID) .build(); accountService.addNewAccount(command); BDDMockito.then(saveAccountPort).should().saveAccount(accountArgumentCaptor.capture()); savedAccount = accountArgumentCaptor.getValue(); } @Test @DisplayName(\u0026#34;Then added account has the given name\u0026#34;) void accountAddedWithGivenName() { BDDAssertions.then(savedAccount.getName()).isEqualTo(ACCOUNT_NAME); } @Test @DisplayName(\u0026#34;Then added account has the given initial balance\u0026#34;) void accountAddedWithGivenInitialBalance() { BDDAssertions.then(savedAccount.getBalance()).isEqualTo(new BigDecimal(INITIAL_BALANCE)); } @Test @DisplayName(\u0026#34;Then added account has user\u0026#39;s id\u0026#34;) void accountAddedWithUsersId() { BDDAssertions.then(accountArgumentCaptor.getValue().getUserId()).isEqualTo(USER_ID); } } @Test @DisplayName(\u0026#34;When user adds a new account with negative initial balance Then add new account fails\u0026#34;) void addNewAccountFailsWithNegativeInitialBalance() { AddNewAccountCommand command = AddNewAccountCommand.builder() .initialBalance(\u0026#34;-56.0\u0026#34;) .build(); assertThatExceptionOfType(IllegalArgumentException.class) .isThrownBy(() -\u0026gt; accountService.addNewAccount(command)); BDDMockito.then(saveAccountPort).shouldHaveNoInteractions(); } } @Test @DisplayName(\u0026#34;Given account with the same name exists When user adds a new account Then add new account fails\u0026#34;) void addNewAccountFailsForDuplicateAccounts() { String existingAccountName = \u0026#34;existing name\u0026#34;; AddNewAccountCommand command = AddNewAccountCommand.builder() .initialBalance(\u0026#34;0\u0026#34;) .accountName(existingAccountName) .build(); given(findAccountPort.findAccountByName(existingAccountName)).willReturn(mock(Account.class)); AddNewAccountService accountService = new AddNewAccountService(saveAccountPort, findAccountPort); assertThatExceptionOfType(IllegalArgumentException.class) .isThrownBy(() -\u0026gt; accountService.addNewAccount(command)); BDDMockito.then(saveAccountPort).shouldHaveNoInteractions(); } } Here\u0026rsquo;s what we did -\nWe created another inner class, marked it as @Nested, and moved our existing passing tests into this. This group of tests test the behaviour of adding a new account when no account with the given name already exists. We have moved our test set up code into the newly introduced inner class as they are also related to the \u0026ldquo;no account with the given name already exists\u0026rdquo; case. For the same reason as above, we have also moved our @DisplayName annotation from the top level test class to the newly introduced inner class.\nAfter our refactoring we quickly run our tests to see if everything is working as expected (failing test failing, passing tests passing), and then move on to modify our service -\n@RequiredArgsConstructor class AddNewAccountService { private final SaveAccountPort saveAccountPort; private final FindAccountPort findAccountPort; void addNewAccount(AddNewAccountCommand command) { BigDecimal initialBalance = new BigDecimal(command.getInitialBalance()); if (initialBalance.compareTo(BigDecimal.ZERO) \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;Initial balance of an account cannot be negative\u0026#34;); } if (findAccountPort.findAccountByName(command.getAccountName()) != null) { throw new IllegalArgumentException(\u0026#34;An account with given name already exists\u0026#34;); } saveAccountPort.saveAccount( new Account( command.getAccountName(), initialBalance, command.getUserId() ) ); } @Builder @Getter static class AddNewAccountCommand { private final String userId; private final String accountName; private final String initialBalance; } } All of our tests should now be green.\nSince our use case implementation is now complete, we will look at our implementation for one last time and see if we can improve anything. If not, our use case implementation is now complete!\nTo summarise, this is what we did throughout this article -\nWe have written down a use case that we would like to implement We have added a failing test, labelling it with a human-readable name We have added the minimal amount of code needed to make the failing test pass As soon as we had more than one passing tests, after we made each failing test pass, we looked at our implementation and tried to improve it When writing the tests we tried writing them in such a way so that our use case specifications are reflected in the test code. For this we have used - The @DisplayName annotation to assign human-readable names to our tests Used @Nested to group related tests in a hierarchical structure, reflecting our use case setup Used BDD-driven API from Mockito and AssertJ to verify the expected behaviours When should we follow this style of writing automated tests? The answer to this question is the same as every other usage questions in Software Engineering - it depends. I personally prefer this style when I am working with an application which has complex business/domain rules, which is intended to be maintained over a long period, for which a close collaboration with the business is required, and many other factors (i.e., application architecture, team adoption etc.).\nAs always, the full working example has been pushed to Github.\nUntil next time!\n","permalink":"https://www.sayemahmed.com/posts/writing-executable-specifications-with-junit5-mockito-and-assertj/","summary":"Executable Specifications are tests that can also serve as design specifications. They enable technical and business teams to get on the same page by enabling the use of a common language (in DDD-world this is also known as Ubiquitous Language). They function as documentations for the future maintainers of the code. In this article we will see an opinionated way of writing automated tests which could also function as Executable Specifications.","title":"Writing Executable Specifications With Junit5 Mockito and AssertJ"},{"content":"Introduction In Java, threads can have States. The Thread.State enum defines the different states that a Java thread can have. This enum defines the following values -\nNEW RUNNABLE BLOCKED WAITING TIMED_WAITING TERMINATED In the subsequent sections I will provide a brief overview of these states along with possible transitions between them.\nStates of a Java Thread NEW This is the default state a thread gets when it is first created.\nRUNNABLE As soon as a thread starts executing, it moves to the RUNNABLE state.\nNote that a thread that is waiting to acquire a CPU for execution is still considered to be in this state.\nBLOCKED A thread moves to the BLOCKED state as soon as it gets blocked waiting for a monitor lock. This can happen in one of the following two ways -\nIt\u0026rsquo;s waiting to acquire a lock to enter a synchronised block/method. It\u0026rsquo;s waiting to reacquire the monitor lock of an object on which it invoked the Object.wait method. WAITING A thread moves to this state as a result of invoking one of the following methods -\nObject.wait without a timeout Thread.join without a timeout LockSupport.park TIMED_WAITING A thread moves to this state as a result of invoking one of the following methods -\nThread.sleep Object.wait with a timeout Thread.join with a timeout LockSupport.parkNanos LockSupport.parkUntil TERMINATED As soon as a thread terminates, it moves to this state.\nPossible state transitions The following diagram shows the possible transitions between different states -\nAs soon as a thread gets scheduled for execution, it moves to the RUNNABLE state. This transition has been shown with the first arrow (marked as 1).\nFrom the RUNNABLE state, a thread can move to any of the BLOCKED, WAITING, TIMED_WAITING, or TERMINATED state. Theoretically speaking, if a thread does not wait to acquire any lock, or does not sleep, or does not invoke any of the methods which makes it wait, it just finishes its execution and directly goes to the TERMINATED state (marked as 2d).\nOf course in a practical application, the above scenario is highly unlikely. Often a thread tries to acquire a lock, in which case it moves to the BLOCKED (marked as 2a) state if it has to wait for the lock. Threads also explicitly wait for some preconditions to be true/actions from other threads, in which case they move to the WAITING (marked as 2b) or the TIMED_WAITING (marked as 2c) state, depending on whether the waits were timed or not.\nOnce a thread moves to the BLOCKED state, the only possible transition that is allowed next is to move to the RUNNABLE state (marked as 3d).\nSimilarly, the only possible transition from the WAITING state is to move to the BLOCKED state (marked as 3c).\nPlease note that some of the articles on the internet incorrectly adds a transition from the WAITING to the RUNNABLE state. This is just not correct. A thread can never move to the RUNNABLE state from the WAITING state directly. We can understand the reason for this with an example.\nSuppose that we have a thread T which is currently in the RUNNABLE state and holds the monitor lock of three objects a, b, and c, as shown in the diagram below -\nAt this point, T invokes c.wait(), after which it no longer holds the monitor lock of object c -\nAs soon as T is notified using an invocation of notify/notifyAll, it stops waiting and competes with other threads (let\u0026rsquo;s say, X and Y) to acquire the monitor lock of c -\nwhich, according to the definitions above, is the BLOCKED state. Only after acquiring the monitor lock of c, T moves to the RUNNABLE state. Similar reasoning can be applied for the Thread.join() (which internally uses Object.wait()) and LockSupport.park().\nLet\u0026rsquo;s get back to our original state transition diagram. As we can see, a thread can move to either the RUNNABLE (marked as 3b) or the BLOCKED (marked as 3a) state from the TIMED_WAITING state. The transition to RUNNABLE is possible in this case because a thread can enter the TIMED_WAITING state after invoking the Thread.sleep method, in which case it retains all the monitor locks it currently holds.\nAs a thread finishes execution after moving back and forth between the RUNNABLE, BLOCKED, WAITING or TIMED_WAITING state, it moves to the TERMINATED state once and for all.\nHow do we get the current state of a Thread? We can use the Thread.getState() method to retrieve the current state of a thread. We can use this value to monitor or debug any concurrency issues that our application might face in production.\nConclusion In this article we briefly reviewed different states a Java thread can have, and how a thread moves between these states. As always, any feedback/improvement suggestions/comments is highly appreciated!\n","permalink":"https://www.sayemahmed.com/posts/different-states-of-java-threads/","summary":"Introduction In Java, threads can have States. The Thread.State enum defines the different states that a Java thread can have. This enum defines the following values -\nNEW RUNNABLE BLOCKED WAITING TIMED_WAITING TERMINATED In the subsequent sections I will provide a brief overview of these states along with possible transitions between them.\nStates of a Java Thread NEW This is the default state a thread gets when it is first created.","title":"Different States of Java Threads"},{"content":"Introduction The Fork/Join framework is a framework to solve a problem using a concurrent divide-and-conquer approach. They were introduced to complement the existing concurrency API. Before their introduction, the existing ExecutorService implementations were the popular choice to run asynchronous tasks, but they work best when the tasks are homogenous and independent. Running dependent tasks and combining their results using those implementations were not easy. With the introduction of the Fork/Join framework, an attempt was made to address this shortcoming. In this post, we will take a brief look at the API and solve a couple of simple problems to understand how they work.\nSolving a non-blocking task Let\u0026rsquo;s jump directly into code. Let\u0026rsquo;s create a task which would return the sum of all elements of a List. The following steps represent our algorithm in pseudo-code:\nFind the middle index of the list Divide the list in the middle Recursively create a new task which will compute the sum of the left part Recursively create a new task which will compute the sum of the right part Add the result of the left sum, the middle element, and the right sum Here is the code -\n@Slf4j public class ListSummer extends RecursiveTask\u0026lt;Integer\u0026gt; { private final List\u0026lt;Integer\u0026gt; listToSum; ListSummer(List\u0026lt;Integer\u0026gt; listToSum) { this.listToSum = listToSum; } @Override protected Integer compute() { if (listToSum.isEmpty()) { log.info(\u0026#34;Found empty list, sum is 0\u0026#34;); return 0; } int middleIndex = listToSum.size() / 2; log.info(\u0026#34;List {}, middle Index: {}\u0026#34;, listToSum, middleIndex); List\u0026lt;Integer\u0026gt; leftSublist = listToSum.subList(0, middleIndex); List\u0026lt;Integer\u0026gt; rightSublist = listToSum.subList(middleIndex + 1, listToSum.size()); ListSummer leftSummer = new ListSummer(leftSublist); ListSummer rightSummer = new ListSummer(rightSublist); leftSummer.fork(); rightSummer.fork(); Integer leftSum = leftSummer.join(); Integer rightSum = rightSummer.join(); int total = leftSum + listToSum.get(middleIndex) + rightSum; log.info(\u0026#34;Left sum is {}, right sum is {}, total is {}\u0026#34;, leftSum, rightSum, total); return total; } } Firstly, we extend the RecursiveTask subtype of the ForkJoinTask. This is the type to extend from when we expect our concurrent task to return a result. When a task does not return a result but only perform an effect, we extend the RecursiveAction subtype. For most of the practical tasks that we solve, these two subtypes are sufficient.\nSecondly, both RecursiveTask and RecursiveAction define an abstract compute method. This is where we put our computation.\nThirdly, inside our compute method, we check the size of the list that is passed through the constructor. If it is empty, we already know the result of the sum which is zero, and we return immediately. Otherwise, we divide our lists into two sublists and create two instances of our ListSummer type. We then call the fork() method (defined in ForkJoinTask) on these two instances -\nleftSummer.fork(); rightSummer.fork(); Which cause these tasks to be scheduled for asynchronous execution, the exact mechanism which is used for this purpose will be explained later in this post.\nAfter that, we invoke the join() method (also defined in ForkJoinTask) to wait for the result of these two parts -\nInteger leftSum = leftSummer.join(); Integer rightSum = rightSummer.join(); Which are then summed with the middle element of the list to get the final result.\nPlenty of log messages have been added to make the example easier to understand. However, when we process a list containing thousands of entries, it might not be a good idea to have this detailed logging, especially logging the entire list.\nThat\u0026rsquo;s pretty much it. Let\u0026rsquo;s create a test class now for a test run -\npublic class ListSummerTest { @Test public void shouldSumEmptyList() { ListSummer summer = new ListSummer(List.of()); ForkJoinPool forkJoinPool = new ForkJoinPool(); forkJoinPool.submit(summer); int result = summer.join(); assertThat(result).isZero(); } @Test public void shouldSumListWithOneElement() { ListSummer summer = new ListSummer(List.of(5)); ForkJoinPool forkJoinPool = new ForkJoinPool(); forkJoinPool.submit(summer); int result = summer.join(); assertThat(result).isEqualTo(5); } @Test public void shouldSumListWithMultipleElements() { ListSummer summer = new ListSummer(List.of( 1, 2, 3, 4, 5, 6, 7, 8, 9 )); ForkJoinPool forkJoinPool = new ForkJoinPool(); forkJoinPool.submit(summer); int result = summer.join(); assertThat(result).isEqualTo(45); } } In the test, we create an instance of the ForkJoinPool. A ForkJoinPool is a unique ExecutorService implementation for running ForkJoinTasks. It employs a special algorithm known as the work-stealing algorithm. Contrary to the other ExecutorService implementations where there is only a single queue holding all the tasks to be executed, in a work-stealing implementation, each worker thread gets its work queue. Each thread starts executing tasks from their queue. When we detect that a ForkJoinTask can be broken down into multiple smaller subtasks, we do break them into smaller tasks, and then we invoke the fork() method on those tasks. This invocation causes the subtasks to be pushed into the executing thread\u0026rsquo;s queue. During the execution, when one thread exhausts its queue/has no tasks to execute, it can \u0026ldquo;steal\u0026rdquo; tasks from other thread\u0026rsquo;s queue (hence the name \u0026ldquo;work-stealing\u0026rdquo;). This stealing behaviour is what results in a better throughput than using any other ExecutorService implementations.\nEarlier, when we invoked fork() on our leftSummer and rightSummer task instances, they got pushed into the work queue of the executing thread, after which they were \u0026ldquo;stolen\u0026rdquo; by other active threads in the pool (and so on) since they did not have anything else to do at that point.\nPretty cool, right?\nSolving a blocking task The problem we solved just now is non-blocking in nature. If we want to solve a problem which does some blocking operation, then to have a better throughput we will need to change our strategy.\nLet\u0026rsquo;s examine this with another example. Let\u0026rsquo;s say we want to create a very simple web crawler. This crawler will receive a list of HTTP links, execute GET requests to fetch the response bodies, and then calculate the response length. Here is the code -\n@Slf4j public class ResponseLengthCalculator extends RecursiveTask\u0026lt;Map\u0026lt;String, Integer\u0026gt;\u0026gt; { private final List\u0026lt;String\u0026gt; links; ResponseLengthCalculator(List\u0026lt;String\u0026gt; links) { this.links = links; } @Override protected Map\u0026lt;String, Integer\u0026gt; compute() { if (links.isEmpty()) { log.info(\u0026#34;No more links to fetch\u0026#34;); return Collections.emptyMap(); } int middle = links.size() / 2; log.info(\u0026#34;Middle index: {}\u0026#34;, links, middle); ResponseLengthCalculator leftPartition = new ResponseLengthCalculator(links.subList(0, middle)); ResponseLengthCalculator rightPartition = new ResponseLengthCalculator(links.subList(middle + 1, links.size())); log.info(\u0026#34;Forking left partition\u0026#34;); leftPartition.fork(); log.info(\u0026#34;Left partition forked, now forking right partition\u0026#34;); rightPartition.fork(); log.info(\u0026#34;Right partition forked\u0026#34;); String middleLink = links.get(middle); HttpRequester httpRequester = new HttpRequester(middleLink); String response; try { log.info(\u0026#34;Calling managedBlock for {}\u0026#34;, middleLink); ForkJoinPool.managedBlock(httpRequester); response = httpRequester.response; } catch (InterruptedException ex) { log.error(\u0026#34;Error occurred while trying to implement blocking link fetcher\u0026#34;, ex); response = \u0026#34;\u0026#34;; } Map\u0026lt;String, Integer\u0026gt; responseMap = new HashMap\u0026lt;\u0026gt;(links.size()); Map\u0026lt;String, Integer\u0026gt; leftLinks = leftPartition.join(); responseMap.putAll(leftLinks); responseMap.put(middleLink, response.length()); Map\u0026lt;String, Integer\u0026gt; rightLinks = rightPartition.join(); responseMap.putAll(rightLinks); log.info(\u0026#34;Left map {}, middle length {}, right map {}\u0026#34;, leftLinks, response.length(), rightLinks); return responseMap; } private static class HttpRequester implements ForkJoinPool.ManagedBlocker { private final String link; private String response; private HttpRequester(String link) { this.link = link; } @Override public boolean block() { HttpGet headRequest = new HttpGet(link); CloseableHttpClient client = HttpClientBuilder .create() .disableRedirectHandling() .build(); log.info(\u0026#34;Executing blocking request for {}\u0026#34;, link); try (client; CloseableHttpResponse response = client.execute(headRequest)) { log.info(\u0026#34;HTTP request for link {} has been executed\u0026#34;, link); this.response = EntityUtils.toString(response.getEntity()); } catch (IOException e) { log.error(\u0026#34;Error while trying to fetch response from link {}: {}\u0026#34;, link, e.getMessage()); this.response = \u0026#34;\u0026#34;; } return true; } @Override public boolean isReleasable() { return false; } } } We create an implementation of the ForkJoinPool.ManagedBlocker where we put the blocking HTTP call. This interface defines two methods - block() and isReleasable(). The block() method is where we put our blocking call. After we are done with our blocking operation, we return true indicating that no further blocking is necessary. We return false from the isReleasable() implementation to indicate to a fork-join worker thread that the block() method implementation is potentially blocking in nature. The isReleasable() implementation will be invoked by a fork-join worker thread first before it invokes the block() method. Finally, we submit our HttpRequester instance to our pool by invoking ForkJoinPool.managedBlock() static method. After that our blocking task will start executing. When it blocks on the HTTP request, the ForkJoinPool.managedBlock() method will also arrange for a spare thread to be activated if necessary to ensure sufficient parallelism.\nLet\u0026rsquo;s take this implementation for a test drive then! Here\u0026rsquo;s the code -\npublic class ResponseLengthCalculatorTest { @Test public void shouldReturnEmptyMapForEmptyList() { ResponseLengthCalculator responseLengthCalculator = new ResponseLengthCalculator(Collections.emptyList()); ForkJoinPool pool = new ForkJoinPool(); pool.submit(responseLengthCalculator); Map\u0026lt;String, Integer\u0026gt; result = responseLengthCalculator.join(); assertThat(result).isEmpty(); } @Test public void shouldHandle200Ok() { ResponseLengthCalculator responseLengthCalculator = new ResponseLengthCalculator(List.of( \u0026#34;http://httpstat.us/200\u0026#34; )); ForkJoinPool pool = new ForkJoinPool(); pool.submit(responseLengthCalculator); Map\u0026lt;String, Integer\u0026gt; result = responseLengthCalculator.join(); assertThat(result) .hasSize(1) .containsKeys(\u0026#34;http://httpstat.us/200\u0026#34;) .containsValue(0); } @Test public void shouldFetchResponseForDifferentResponseStatus() { ResponseLengthCalculator responseLengthCalculator = new ResponseLengthCalculator(List.of( \u0026#34;http://httpstat.us/200\u0026#34;, \u0026#34;http://httpstat.us/302\u0026#34;, \u0026#34;http://httpstat.us/404\u0026#34;, \u0026#34;http://httpstat.us/502\u0026#34; )); ForkJoinPool pool = new ForkJoinPool(); pool.submit(responseLengthCalculator); Map\u0026lt;String, Integer\u0026gt; result = responseLengthCalculator.join(); assertThat(result) .hasSize(4); } } That\u0026rsquo;s it for today, folks! As always, any feedback/improvement suggestions/comments are highly appreciated!\nAll the examples discussed here can be found on Github.\nA big shout out to the awesome http://httpstat.us service, it was quite helpful for developing the simple tests.\n","permalink":"https://www.sayemahmed.com/posts/a-brief-overview-of-the-fork-join-framework-in-java/","summary":"Introduction The Fork/Join framework is a framework to solve a problem using a concurrent divide-and-conquer approach. They were introduced to complement the existing concurrency API. Before their introduction, the existing ExecutorService implementations were the popular choice to run asynchronous tasks, but they work best when the tasks are homogenous and independent. Running dependent tasks and combining their results using those implementations were not easy. With the introduction of the Fork/Join framework, an attempt was made to address this shortcoming.","title":"A Brief Overview of the Fork Join Framework in Java"},{"content":"In this article we will be extending an ExecutorService implementation with monitoring capabilities. This monitoring capability will help us to measure a number of pool parameters i.e., active threads, work queue size etc. in a live production environment. It will also enable us to measure task execution time, successful tasks count, and failed tasks count.\nMonitoring Library As for the monitoring library we will be using Metrics. For the sake of simplicity we will be using a ConsoleReporter which will report our metrics to the console. For production-grade applications, we should use an advanced reporter (i.e., Graphite reporter). If you are unfamiliar with Metrics, then I recommend you to go through the getting started guide.\nLet\u0026rsquo;s get started.\nExtending the ThreadPoolExecutor We will be using ThreadPoolExecutor as the base class for our new type. Let\u0026rsquo;s call it MonitoredThreadPoolExecutor. This class will accept a MetricRegistry as one of its constructor parameters -\npublic class MonitoredThreadPoolExecutor extends ThreadPoolExecutor { private final MetricRegistry metricRegistry; public MonitoredThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, MetricRegistry metricRegistry ) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); this.metricRegistry = metricRegistry; } public MonitoredThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, MetricRegistry metricRegistry ) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory); this.metricRegistry = metricRegistry; } public MonitoredThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, RejectedExecutionHandler handler, MetricRegistry metricRegistry ) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); this.metricRegistry = metricRegistry; } public MonitoredThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler, MetricRegistry metricRegistry ) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); this.metricRegistry = metricRegistry; } } Registering Gauges to measure pool-specific paramters A Gauge is an instantaneous measurement of a value. We will be using it to measure different pool parameters like number of active threads, task queue size etc.\nBefore we can register a Gauge, we need to decide how to calculate a metric name for our thread pool. Each metric, whether it\u0026rsquo;s a Gauge, or a Timer, or simply a Meter, has a unique name. This name is used to identify the metric source. The convention here is to use a dotted string which is often constructed from the fully qualified name of the class being monitored.\nFor our thread pool, we will be using its fully qualified name as a prefix to our metrics names. Additionally we will add another constructor parameter called poolName, which will be used by the clients to specify instance-specific identifiers.\nAfter implementing these changes the class looks like below -\npublic class MonitoredThreadPoolExecutor extends ThreadPoolExecutor { private final MetricRegistry metricRegistry; private final String metricsPrefix; public MonitoredThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, MetricRegistry metricRegistry, String poolName ) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); this.metricRegistry = metricRegistry; this.metricsPrefix = MetricRegistry.name(getClass(), poolName); } // Rest of the constructors } Now we are ready to register our Gauges. For this purpose we will define a private method -\nprivate void registerGauges() { metricRegistry.register(MetricRegistry.name(metricsPrefix, \u0026#34;corePoolSize\u0026#34;), (Gauge\u0026lt;Integer\u0026gt;) this::getCorePoolSize); metricRegistry.register(MetricRegistry.name(metricsPrefix, \u0026#34;activeThreads\u0026#34;), (Gauge\u0026lt;Integer\u0026gt;) this::getActiveCount); metricRegistry.register(MetricRegistry.name(metricsPrefix, \u0026#34;maxPoolSize\u0026#34;), (Gauge\u0026lt;Integer\u0026gt;) this::getMaximumPoolSize); metricRegistry.register(MetricRegistry.name(metricsPrefix, \u0026#34;queueSize\u0026#34;), (Gauge\u0026lt;Integer\u0026gt;) () -\u0026gt; getQueue().size()); } For our example we are measuring core pool size, number of active threads, maximum pool size, and task queue size. Depending on monitoring requirements we can register more/less Gauges to measure different properties.\nThis private method will now be invoked from all constructors -\npublic MonitoredThreadPoolExecutor( int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, MetricRegistry metricRegistry, String poolName ) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); this.metricRegistry = metricRegistry; this.metricsPrefix = MetricRegistry.name(getClass(), poolName); registerGauges(); } Measuring Task Execution Time To measure the task execution time, we will override two life-cycle methods that ThreadPoolExecutor provides - beforeExecute and afterExecute.\nAs the name implies, beforeExecute callback is invoked prior to executing a task, by the thread that will execute the task. The default implementation of this callback does nothing.\nSimilarly, the afterExecute callback is invoked after each task is executed, by the thread that executed the task. The default implementation of this callback also does nothing. Even if the task throws an uncaught RuntimeException or Error, this callback will be invoked.\nWe will be starting a Timer in our beforeExecute override, which will then be used in our afterExecute override to get the total task execution time. To store a reference to the Timer we will introduce a new ThreadLocal field in our class.\nThe implementation of the callbacks are given below -\npublic class MonitoredThreadPoolExecutor extends ThreadPoolExecutor { private final MetricRegistry metricRegistry; private final String metricsPrefix; private ThreadLocal\u0026lt;Timer.Context\u0026gt; taskExecutionTimer = new ThreadLocal\u0026lt;\u0026gt;(); // Constructors @Override protected void beforeExecute(Thread thread, Runnable task) { super.beforeExecute(thread, task); Timer timer = metricRegistry.timer(MetricRegistry.name(metricsPrefix, \u0026#34;task-execution\u0026#34;)); taskExecutionTimer.set(timer.time()); } @Override protected void afterExecute(Runnable task, Throwable throwable) { Timer.Context context = taskExecutionTimer.get(); context.stop(); super.afterExecute(task, throwable); } } Recording number of failed tasks due to uncaught exceptions The second parameter to the afterExecute callback is a Throwable. If non-null, this Throwable refers to the uncaught RuntimeException or Error that caused the execution to terminate. We can use this information to partially count the total number of tasks that were terminated abruptly due to uncaught exceptions.\nTo get the total number of failed tasks, we must consider another case. Tasks submitted using the execute method will throw any uncaught exceptions, and it will be available as the second argument to the afterExecute callback. However, tasks submitted using the submit method are swallowed by the executor service. This is clearly explained in the JavaDoc (emphasis mine) -\nNote: When actions are enclosed in tasks (such as FutureTask) either explicitly or via methods such as submit, these task objects catch and maintain computational exceptions, and so they do not cause abrupt termination, and the internal exceptions are not passed to this method. If you would like to trap both kinds of failures in this method, you can further probe for such cases, as in this sample subclass that prints either the direct cause or the underlying exception if a task has been aborted\nFortunately, the same doc also offers a solution for this, which is to examine the runnable to see if it\u0026rsquo;s a Future, and then get the underlying exception.\nCombining these approaches, we can modify our afterExecute method as follows -\n@Override protected void afterExecute(Runnable runnable, Throwable throwable) { Timer.Context context = taskExecutionTimer.get(); context.stop(); super.afterExecute(runnable, throwable); if (throwable == null \u0026amp;\u0026amp; runnable instanceof Future \u0026amp;\u0026amp; ((Future) runnable).isDone()) { try { ((Future) runnable).get(); } catch (CancellationException ce) { throwable = ce; } catch (ExecutionException ee) { throwable = ee.getCause(); } catch (InterruptedException ie) { Thread.currentThread().interrupt(); } } if (throwable != null) { Counter failedTasksCounter = metricRegistry.counter(MetricRegistry.name(metricsPrefix, \u0026#34;failed-tasks\u0026#34;)); failedTasksCounter.inc(); } } Counting total number of successful tasks The previous approach can also be used to count the total number of successful tasks: tasks that were completed without throwing any exceptions or errors -\n@Override protected void afterExecute(Runnable runnable, Throwable throwable) { // Rest of the method body ..... if (throwable != null) { Counter failedTasksCounter = metricRegistry.counter(MetricRegistry.name(metricsPrefix, \u0026#34;failed-tasks\u0026#34;)); failedTasksCounter.inc(); } else { Counter successfulTasksCounter = metricRegistry.counter(MetricRegistry.name(metricsPrefix, \u0026#34;successful-tasks\u0026#34;)); successfulTasksCounter.inc(); } } Conclusion In this article we have looked at a few monitoring-friendly customization to an ExecutorService implementation. Like always, any suggestions/improvements/bug fix will be highly appreciated. As for the example source code, it has been uploaded to Github.\n","permalink":"https://www.sayemahmed.com/posts/java-tips-creating-a-monitoring-friendly-executorservice/","summary":"In this article we will be extending an ExecutorService implementation with monitoring capabilities. This monitoring capability will help us to measure a number of pool parameters i.e., active threads, work queue size etc. in a live production environment. It will also enable us to measure task execution time, successful tasks count, and failed tasks count.\nMonitoring Library As for the monitoring library we will be using Metrics. For the sake of simplicity we will be using a ConsoleReporter which will report our metrics to the console.","title":"Java Tips: Creating a Monitoring-friendly ExecutorService"},{"content":"Introduction ORM frameworks like JPA simplifies our development process by helping us to avoid lots of boilerplate code during the object \u0026lt;-\u0026gt; relational data mapping. However, they also bring some additional problems to the table, and N + 1 is one of them. In this article we will take a short look at the problem along with some ways to avoid them.\nThe Problem As an example I will use a simplified version of an online book ordering application. In such application I might create an entity like below to represent a Purchase Order -\n@Entity public class PurchaseOrder { @Id private String id; private String customerId; @OneToMany(cascade = ALL, fetch = EAGER) @JoinColumn(name = \u0026#34;purchase_order_id\u0026#34;) private List\u0026lt;PurchaseOrderItem\u0026gt; purchaseOrderItems = new ArrayList\u0026lt;\u0026gt;(); } A purchase order consists of an order id, a customer id, and one or more items that are being bought. The PurchaseOrderItem entity might have the following structure -\n@Entity public class PurchaseOrderItem { @Id private String id; private String bookId; } These entities have been simplified a lot, but for the purpose of this article, this will do.\nNow suppose that we need to find the orders of a customer to display them in his purchase order history. The following query will serve this purpose -\nSELECT P FROM PurchaseOrder P WHERE P.customerId = :customerId which when translated to SQL looks something like below -\nselect purchaseor0_.id as id1_1_, purchaseor0_.customer_id as customer2_1_ from purchase_order purchaseor0_ where purchaseor0_.customer_id = ? This one query will return all purchase orders that a customer has. However, in order to fetch the order items, JPA will issue separate queries for each individual order. If, for example, a customer has 5 orders, then JPA will issue 5 additional queries to fetch the order items included in those orders. This is basically known as the N + 1 problem - 1 query to fetch all N purchase orders, and N queries to fetch all order items.\nThis behavior creates a scalability problem for us when our data grows. Even a moderate number of orders and items can create significant performance issues.\nThe Solution Avoiding Eager Fetching This the main reason behind the issue. We should get rid of all the eager fetching from our mapping. They have almost no benefits that justify their use in a production-grade application. We should mark all relationships as Lazy instead.\nOne important point to note - marking a relationship mapping as Lazy does not guarantee that the underlying persistent provider will also treat it as such. The JPA specification does not guarantee the lazy fetch. It\u0026rsquo;s a hint to the persistent provider at best. However, considering Hibernate, I have never seen it doing otherwise.\nOnly fetching the data that are actually needed This is always recommended regardless of the decision to go for eager/lazy fetching.\nI remember one N + 1 optimization that I did which improved the maximum response time of a REST endpoint from 17 minutes to 1.5 seconds. The endpoint was fetching a single entity based on some criteria, which for our current example will be something along the line of -\nTypedQuery\u0026lt;PurchaseOrder\u0026gt; jpaQuery = entityManager.createQuery(\u0026#34;SELECT P FROM PurchaseOrder P WHERE P.customerId = :customerId\u0026#34;, PurchaseOrder.class); jpaQuery.setParameter(\u0026#34;customerId\u0026#34;, \u0026#34;Sayem\u0026#34;); PurchaseOrder purchaseOrder = jpaQuery.getSingleResult(); // after some calculation anotherRepository.findSomeStuff(purchaseOrder.getId()); The id is the only data from the result that was needed for subsequent calculations.\nThere were a few customers who had more than a thousand orders. Each one of the orders in turn had a few thousands additional children of a few different types. Needless to say, as a result, thousands of queries were being executed in the database whenever requests for those orders were received at this endpoint.\nTo improve the performance, all I did was -\nTypedQuery\u0026lt;String\u0026gt; jpaQuery = entityManager.createQuery(\u0026#34;SELECT P.id FROM PurchaseOrder P WHERE P.customerId = :customerId\u0026#34;, String.class); jpaQuery.setParameter(\u0026#34;customerId\u0026#34;, \u0026#34;Sayem\u0026#34;); String orderId = jpaQuery.getSingleResult(); // after some calculation anotherRepository.findSomeStuff(orderId); Just this change resulted in a 680x improvement.\nIf we want to fetch more than one properties, then we can make use of the Constructor Expression that JPA provides -\nTypedQuery\u0026lt;PurchaseOrderDTO\u0026gt; jpaQuery = entityManager.createQuery( \u0026#34;SELECT \u0026#34; + \u0026#34;NEW com.codesod.example.jpa.nplusone.dto.PurchaseOrderDTO(P.id, P.orderDate) \u0026#34; + \u0026#34;FROM \u0026#34; + \u0026#34;PurchaseOrder P \u0026#34; + \u0026#34;WHERE \u0026#34; + \u0026#34;P.customerId = :customerId\u0026#34;, PurchaseOrderDTO.class); jpaQuery.setParameter(\u0026#34;customerId\u0026#34;, \u0026#34;Sayem\u0026#34;); List\u0026lt;PurchaseOrderDTO\u0026gt; orders = jpaQuery.getResultList(); A few caveats of using the constructor expression -\nThe target DTO must have a constructor whose parameter list match the columns being seleected The fully qualified name of the DTO class must be specified Useing Join Fetch / Entity Graphs We can use JOIN FETCH in our queries whenever we need to fetch an entity with all of its children at the same time. This results in a much less database traffic resulting in an improved performance.\nJPA 2.1 specification introduced Entity Graphs which allows us to create static/dynamic query load plans. Thorben Janssen has written a couple of posts (here and here) detailing their usage which are worth checking out.\nSome example code for this post can be found at Github.\n","permalink":"https://www.sayemahmed.com/posts/jpa-tips-avoiding-the-n-plus-1-select-problem/","summary":"Introduction ORM frameworks like JPA simplifies our development process by helping us to avoid lots of boilerplate code during the object \u0026lt;-\u0026gt; relational data mapping. However, they also bring some additional problems to the table, and N + 1 is one of them. In this article we will take a short look at the problem along with some ways to avoid them.\nThe Problem As an example I will use a simplified version of an online book ordering application.","title":"Jpa Tips: Avoiding the N + 1 Select Problem"},{"content":"Let\u0026rsquo;s directly start with an example. Consider a simple web service which allows clients to place order to a shop. A very simplified version of the order controller could look something like below -\n@RestController @RequestMapping(value = \u0026#34;/\u0026#34;, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE) public class OrderController { private final OrderService orderService; public OrderController(OrderService orderService) { this.orderService = orderService; } @PostMapping public void doSomething(@Valid @RequestBody OrderDTO order) { orderService.createOrder(order); } } And the corresponding DTO class -\n@Getter @Setter @ToString public class OrderDTO { @NotNull private String customerId; @NotNull @Size(min = 1) private List\u0026lt;OrderItem\u0026gt; orderItems; @Getter @Setter @ToString public static class OrderItem { private String menuId; private String description; private String price; private Integer quantity; } } The most common approach for creating an order from this DTO is to pass it to a service, validate it as necessary, and then persist it in the database -\n@Service @Slf4j class OrderService { private final MenuRepository menuRepository; OrderService(MenuRepository menuRepository) { this.menuRepository = menuRepository; } void createOrder(OrderDTO orderDTO) { orderDTO.getOrderItems() .forEach(this::validate); log.info(\u0026#34;Order {} saved\u0026#34;, orderDTO); } private void validate(OrderItem orderItem) { String menuId = orderItem.getMenuId(); if (menuId == null || menuId.trim().isEmpty()) { throw new IllegalArgumentException(\u0026#34;A menu item must be specified.\u0026#34;); } if (!menuRepository.menuExists(menuId.trim())) { throw new IllegalArgumentException(\u0026#34;Given menu \u0026#34; + menuId + \u0026#34; does not exist.\u0026#34;); } String description = orderItem.getDescription(); if (description == null || description.trim().isEmpty()) { throw new IllegalArgumentException(\u0026#34;Item description should be provided\u0026#34;); } String price = orderItem.getPrice(); if (price == null || price.trim().isEmpty()) { throw new IllegalArgumentException(\u0026#34;Price cannot be empty.\u0026#34;); } try { new BigDecimal(price); } catch (NumberFormatException ex) { throw new IllegalArgumentException(\u0026#34;Given price is not in valid format\u0026#34;, ex); } if (orderItem.getQuantity() == null) { throw new IllegalArgumentException(\u0026#34;Quantity must be given\u0026#34;); } if (orderItem.getQuantity() \u0026lt;= 0) { throw new IllegalArgumentException(\u0026#34;Given quantity \u0026#34; + orderItem.getQuantity() + \u0026#34; is not valid.\u0026#34;); } } } The validate method is not well written. It is very hard to test. Introducing new validation rule in the future is also hard, and so is removing/modifying any of the existing ones. From my experience I have seen that most people write a few generic assertions for this type of validation check, typically in an integration test class, touching only one or two (or more, but not all) of the validation rules. As a result, refactoring in the future can only be done in Edit and Pray mode.\nWe can improve the code structure if we use Polymorphism to replace these conditionals. Let\u0026rsquo;s create a common super type for representing a single validation rule -\npublic interface OrderItemValidator { void validate(OrderItem orderItem); } Next step is to create validation rule implementations which will focus on separate validation areas for the DTO. Let\u0026rsquo;s start with the menu validator -\npublic class MenuValidator implements OrderItemValidator { private final MenuRepository menuRepository; public MenuValidator(MenuRepository menuRepository) { this.menuRepository = menuRepository; } @Override public void validate(OrderItem orderItem) { String menuId = Optional.ofNullable(orderItem.getMenuId()) .map(String::trim) .filter(id -\u0026gt; !id.isEmpty()) .orElseThrow(() -\u0026gt; new IllegalArgumentException(\u0026#34;A menu item must be specified.\u0026#34;)); if (!menuRepository.menuExists(menuId)) { throw new IllegalArgumentException(\u0026#34;Given menu [\u0026#34; + menuId + \u0026#34;] does not exist.\u0026#34;); } } } Then the item description validator -\npublic class ItemDescriptionValidator implements OrderItemValidator { @Override public void validate(OrderItem orderItem) { Optional.ofNullable(orderItem) .map(OrderItem::getDescription) .map(String::trim) .filter(description -\u0026gt; !description.isEmpty()) .orElseThrow(() -\u0026gt; new IllegalArgumentException(\u0026#34;Item description should be provided\u0026#34;)); } } Price validator -\npublic class PriceValidator implements OrderItemValidator { @Override public void validate(OrderItem orderItem) { String price = Optional.ofNullable(orderItem) .map(OrderItem::getPrice) .map(String::trim) .filter(itemPrice -\u0026gt; !itemPrice.isEmpty()) .orElseThrow(() -\u0026gt; new IllegalArgumentException(\u0026#34;Price cannot be empty.\u0026#34;)); try { new BigDecimal(price); } catch (NumberFormatException ex) { throw new IllegalArgumentException(\u0026#34;Given price [\u0026#34; + price + \u0026#34;] is not in valid format\u0026#34;, ex); } } } And finally, the quantity validator -\npublic class QuantityValidator implements OrderItemValidator { @Override public void validate(OrderItem orderItem) { Integer quantity = Optional.ofNullable(orderItem) .map(OrderItem::getQuantity) .orElseThrow(() -\u0026gt; new IllegalArgumentException(\u0026#34;Quantity must be given\u0026#34;)); if (quantity \u0026lt;= 0) { throw new IllegalArgumentException(\u0026#34;Given quantity \u0026#34; + quantity + \u0026#34; is not valid.\u0026#34;); } } } Each of these validator implementations can now be easily tested, independently from each other. Reasoning about each one of them also becomes easier. and so are future addition/modification/removal.\nNow the wiring part. How can we integrate these validators with the order service?\nOne way would be to directly create a list in the OrderService constructor, and populate it with the validators. Or we could use Spring to inject a List into the OrderService -\n@Service @Slf4j class OrderService { private final List\u0026lt;OrderItemValidator\u0026gt; validators; OrderService(List\u0026lt;OrderItemValidator\u0026gt; validators) { this.validators = validators; } void createOrder(OrderDTO orderDTO) { orderDTO.getOrderItems() .forEach(this::validate); log.info(\u0026#34;Order {} saved\u0026#34;, orderDTO); } private void validate(OrderItem orderItem) { validators.forEach(validator -\u0026gt; validator.validate(orderItem)); } } In order for this to work we will have to declare each of the validator implementations as a Spring Bean.\nWe could improve our abstraction even further. The OrderService is now accepting a List of the validators. However, we can change it to be only aware of the OrderItemValidator type, and nothing else. This gives us the flexibility of injecting either a single validator or any composition of validators in the future.\nSo now our goal is to change the order service to treat a composition of order item validators in the same way as a single validator. There is a well-known design pattern called Composite which lets us do exactly that.\nLet\u0026rsquo;s create a new implementation of the validator interface, which will be the composite -\nclass OrderItemValidatorComposite implements OrderItemValidator { private final List\u0026lt;OrderItemValidator\u0026gt; validators; OrderItemValidatorComposite(List\u0026lt;OrderItemValidator\u0026gt; validators) { this.validators = validators; } @Override public void validate(OrderItem orderItem) { validators.forEach(validator -\u0026gt; validator.validate(orderItem)); } } We then create a new Spring configuration class, which will instantiate and initialize this composite, and then expose it as a bean -\n@Configuration class ValidatorConfiguration { @Bean OrderItemValidator orderItemValidator(MenuRepository menuRepository) { return new OrderItemValidatorComposite(Arrays.asList( new MenuValidator(menuRepository), new ItemDescriptionValidator(), new PriceValidator(), new QuantityValidator() )); } } We then change the OrderService class in the following way -\n@Service @Slf4j class OrderService { private final OrderItemValidator validator; OrderService(OrderItemValidator orderItemValidator) { this.validator = orderItemValidator; } void createOrder(OrderDTO orderDTO) { orderDTO.getOrderItems() .forEach(validator::validate); log.info(\u0026#34;Order {} saved\u0026#34;, orderDTO); } } And we are done!\nThe benefits of this approach are many. The whole validation logic has completely been abstracted away from the ordering service. Testing is easier. Future maintenance is easier. Clients only know about one validator type, and nothing else.\nHowever, all of the above come with some problems too. Sometimes people are not comfortable with this design. They may feel like this is just too much abstraction, or that they will not be needing this much flexibility or testability for future maintenance. I\u0026rsquo;d suggest to adopt this approach based on the team culture. After all, there is no single right way of doing things in Software Development.\nNote that for the sake of this article I have taken some short cuts here as well. These includes throwing a generic IllegalArgumentException when validation fails. You\u0026rsquo;d probably want a more specific/custom exception in a production-grade application to identify between different scenarios. The decimal parsing is also done naively, you might want to fix on a specific format, and then use DecimalFormat to parse it.\nThe full code has been uploaded to Github.\nIf you find any typo/other errors please feel free to comment in!\n","permalink":"https://www.sayemahmed.com/posts/clean-code-from-the-trenches-validation/","summary":"Let\u0026rsquo;s directly start with an example. Consider a simple web service which allows clients to place order to a shop. A very simplified version of the order controller could look something like below -\n@RestController @RequestMapping(value = \u0026#34;/\u0026#34;, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE) public class OrderController { private final OrderService orderService; public OrderController(OrderService orderService) { this.orderService = orderService; } @PostMapping public void doSomething(@Valid @RequestBody OrderDTO order) { orderService.createOrder(order); } } And the corresponding DTO class -","title":"Clean Code From the Trenches Validation"}]